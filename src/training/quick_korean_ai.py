import openai
import streamlit as st
import os
import asyncio
import time
from datetime import datetime
import threading
from concurrent.futures import ThreadPoolExecutor

# OpenAI API í‚¤ ì„¤ì •
api_key = os.getenv("OPEN_API_KEY") or os.getenv("OPENAI_API_KEY")
if not api_key:
    try:
        api_key = st.secrets.get("OPENAI_API_KEY")
    except:
        pass
        
if not api_key:
    st.error("âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! í™˜ê²½ë³€ìˆ˜ OPEN_API_KEY ë˜ëŠ” OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()

openai.api_key = api_key

# í•œêµ­ì–´ ì°½ì‘ ì „ë¬¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
KOREAN_CREATIVE_PROMPT = """ë‹¹ì‹ ì€ í•œêµ­ì–´ ì°½ì‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

íŠ¹ì§•:
- ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì‚¬ìš©
- ì°½ì˜ì ì´ê³  í¥ë¯¸ë¡œìš´ ìŠ¤í† ë¦¬
- ì ì ˆí•œ ë†’ì„ë²•ê³¼ ë¬¸ì²´
- í•œêµ­ì  ì •ì„œì™€ ë¬¸í™” ë°˜ì˜

ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì†Œì„¤, ì‹œë‚˜ë¦¬ì˜¤, ì—ì„¸ì´ ë“±ì„ ì°½ì‘í•´ì£¼ì„¸ìš”."""

# ì¥ë¥´ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸
GENRE_PROMPTS = {
    "íŒíƒ€ì§€": """ë‹¹ì‹ ì€ í•œêµ­ íŒíƒ€ì§€ ì†Œì„¤ ì‘ê°€ì…ë‹ˆë‹¤.
    
íŠ¹ì§•:
- í•œêµ­ì  ì •ì„œì™€ ì„œêµ¬ íŒíƒ€ì§€ì˜ ì¡°í™”
- ì „í†µ ì‹ í™” ìš”ì†Œ í™œìš©
- í˜„ëŒ€ì  ê°ˆë“± êµ¬ì¡°
- ê°ì •ì  ëª°ì…ë„ ë†’ì€ ë¬¸ì²´

ë‹¤ìŒ ìš”ì²­ì— ë”°ë¼ ì°½ì‘í•´ì£¼ì„¸ìš”:""",

    "ë¡œë§¨ìŠ¤": """ë‹¹ì‹ ì€ í•œêµ­ ë¡œë§¨ìŠ¤ ì†Œì„¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    
íŠ¹ì§•:
- ì„¬ì„¸í•œ ê°ì • ë¬˜ì‚¬
- í•œêµ­ì  ì—°ì•  ë¬¸í™” ë°˜ì˜
- í˜„ì‹¤ì ì´ë©´ì„œë„ ë¡œë§¨í‹±
- ë…ìì˜ ê°ì • ì´ì… ìœ ë„

ë‹¤ìŒ ìš”ì²­ì— ë”°ë¼ ì°½ì‘í•´ì£¼ì„¸ìš”:""",

    "SF": """ë‹¹ì‹ ì€ í•œêµ­ SF ì†Œì„¤ ì‘ê°€ì…ë‹ˆë‹¤.
    
íŠ¹ì§•:
- ê³¼í•™ì  ìƒìƒë ¥ê³¼ í•œêµ­ì  í˜„ì‹¤ì˜ ê²°í•©
- ì‚¬íšŒ ë¹„íŒì  ìš”ì†Œ í¬í•¨
- ë¯¸ë˜ ê¸°ìˆ ê³¼ ì¸ê°„ì„±ì˜ ê°ˆë“±
- ë…¼ë¦¬ì ì´ë©´ì„œë„ ê°ì„±ì 

ë‹¤ìŒ ìš”ì²­ì— ë”°ë¼ ì°½ì‘í•´ì£¼ì„¸ìš”:""",

    "ë¯¸ìŠ¤í„°ë¦¬": """ë‹¹ì‹ ì€ í•œêµ­ ë¯¸ìŠ¤í„°ë¦¬ ì†Œì„¤ ì‘ê°€ì…ë‹ˆë‹¤.
    
íŠ¹ì§•:
- ì¹˜ë°€í•œ ì¶”ë¦¬ì™€ ë°˜ì „
- í•œêµ­ ì‚¬íšŒì˜ í˜„ì‹¤ ë°˜ì˜
- ê¸´ì¥ê° ë„˜ì¹˜ëŠ” ì „ê°œ
- ë…ìì˜ í˜¸ê¸°ì‹¬ ìê·¹

ë‹¤ìŒ ìš”ì²­ì— ë”°ë¼ ì°½ì‘í•´ì£¼ì„¸ìš”:""",

    "ë“œë¼ë§ˆ": """ë‹¹ì‹ ì€ í•œêµ­ ë“œë¼ë§ˆ ì‘ê°€ì…ë‹ˆë‹¤.
    
íŠ¹ì§•:
- ì¼ìƒì ì´ë©´ì„œë„ ê°ë™ì ì¸ ìŠ¤í† ë¦¬
- í•œêµ­ ê°€ì¡± ë¬¸í™” ë°˜ì˜
- í˜„ì‹¤ì ì¸ ê°ˆë“±ê³¼ í•´ê²°
- ë”°ëœ»í•œ ì¸ê°„ë¯¸

ë‹¤ìŒ ìš”ì²­ì— ë”°ë¼ ì°½ì‘í•´ì£¼ì„¸ìš”:"""
}

def generate_korean_content_with_progress(prompt, genre="ì†Œì„¤", temperature=0.8, max_tokens=1000):
    """ì§„í–‰ìƒí™© í‘œì‹œì™€ í•¨ê»˜ í•œêµ­ì–´ ì°½ì‘ ìƒì„±"""
    
    # ì§„í–‰ìƒí™© í‘œì‹œ
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("ğŸ¤– AI ëª¨ë¸ ì¤€ë¹„ ì¤‘...")
        progress_bar.progress(10)
        time.sleep(0.5)
        
        system_prompt = GENRE_PROMPTS.get(genre, KOREAN_CREATIVE_PROMPT)
        
        status_text.text("âœï¸ ì°½ì‘ ì‹œì‘...")
        progress_bar.progress(30)
        time.sleep(0.5)
        
        # OpenAI API í˜¸ì¶œ
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=0.9,
            stream=True  # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ íƒ€ì„ì•„ì›ƒ ë°©ì§€
        )
        
        status_text.text("ğŸ“ í…ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
        progress_bar.progress(60)
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
        full_response = ""
        for chunk in response:
            if chunk.choices[0].delta.content is not None:
                full_response += chunk.choices[0].delta.content
        
        progress_bar.progress(90)
        status_text.text("âœ… ì™„ë£Œ!")
        time.sleep(0.5)
        
        progress_bar.progress(100)
        status_text.text("ğŸ‰ ì°½ì‘ ì™„ë£Œ!")
        
        # UI ì •ë¦¬
        time.sleep(1)
        progress_bar.empty()
        status_text.empty()
        
        return full_response
    
    except Exception as e:
        progress_bar.empty()
        status_text.empty()
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def generate_korean_content(prompt, genre="ì†Œì„¤", temperature=0.8, max_tokens=1000):
    """ê¸°ì¡´ í•¨ìˆ˜ (ë°±ì—…ìš©)"""
    try:
        system_prompt = GENRE_PROMPTS.get(genre, KOREAN_CREATIVE_PROMPT)
        
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=0.9
        )
        
        return response.choices[0].message.content
    
    except Exception as e:
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def main():
    st.set_page_config(
        page_title="ğŸ‡°ğŸ‡· í•œêµ­ì–´ ì°½ì‘ AI",
        page_icon="âœï¸",
        layout="wide"
    )
    
    # í—¤ë”
    st.title("ğŸ‡°ğŸ‡· í•œêµ­ì–´ ì°½ì‘ AI")
    st.markdown("**30ë¶„ ë§Œì— ë§Œë“  ì‹¤ìš©ì ì¸ í•œêµ­ì–´ ì°½ì‘ ë„êµ¬** ğŸš€")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ì¥ë¥´ ì„ íƒ
        genre = st.selectbox(
            "ì¥ë¥´ ì„ íƒ",
            ["íŒíƒ€ì§€", "ë¡œë§¨ìŠ¤", "SF", "ë¯¸ìŠ¤í„°ë¦¬", "ë“œë¼ë§ˆ"],
            index=0
        )
        
        # ê³ ê¸‰ ì„¤ì •
        st.subheader("ê³ ê¸‰ ì„¤ì •")
        temperature = st.slider("ì°½ì˜ì„± (Temperature)", 0.1, 1.0, 0.8, 0.1)
        max_tokens = st.slider("ìµœëŒ€ ê¸¸ì´", 200, 2000, 1000, 100)
        
        # ë¹„ìš© ê³„ì‚°
        st.subheader("ğŸ’° ì˜ˆìƒ ë¹„ìš©")
        cost_per_request = 0.0005  # ì‹¤ì œ ê³„ì‚°ëœ ë¹„ìš©
        st.write(f"ìš”ì²­ë‹¹: ${cost_per_request:.4f}")
        st.write(f"ì›” 1000íšŒ: ${cost_per_request * 1000:.2f}")
    
    # ë©”ì¸ ì½˜í…ì¸ 
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ“ ì°½ì‘ ìš”ì²­")
        
        # ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸
        examples = {
            "íŒíƒ€ì§€": "ë§ˆë²•ì‚¬ í•™êµì— ì…í•™í•œ í‰ë²”í•œ í•™ìƒì´ ìˆ¨ê²¨ì§„ ëŠ¥ë ¥ì„ ë°œê²¬í•˜ëŠ” ì´ì•¼ê¸°",
            "ë¡œë§¨ìŠ¤": "ì¹´í˜ì—ì„œ ìš°ì—°íˆ ë§Œë‚œ ë‘ ì‚¬ëŒì˜ ìš´ëª…ì ì¸ ì‚¬ë‘ ì´ì•¼ê¸°",
            "SF": "AIê°€ ì¸ê°„ì˜ ê°ì •ì„ ì´í•´í•˜ê²Œ ë˜ë©´ì„œ ë²Œì–´ì§€ëŠ” ì¼",
            "ë¯¸ìŠ¤í„°ë¦¬": "ì—°ì‡„ ì‹¤ì¢… ì‚¬ê±´ì„ ìˆ˜ì‚¬í•˜ëŠ” í˜•ì‚¬ì˜ ì´ì•¼ê¸°",
            "ë“œë¼ë§ˆ": "ê°€ì¡±ì˜ ë¹„ë°€ì´ ë°í˜€ì§€ë©´ì„œ ë²Œì–´ì§€ëŠ” ê°ˆë“±ê³¼ í™”í•´"
        }
        
        example_prompt = examples.get(genre, "")
        
        # í”„ë¡¬í”„íŠ¸ ì…ë ¥
        prompt = st.text_area(
            "ì°½ì‘ ìš”ì²­ì„ ì…ë ¥í•˜ì„¸ìš”",
            value="",
            height=150,
            placeholder=f"ì˜ˆì‹œ: {example_prompt}"
        )
        
        # ìƒì„± ë²„íŠ¼
        if st.button("âœ¨ ì°½ì‘í•˜ê¸°", type="primary"):
            if prompt.strip():
                # ì§„í–‰ìƒí™©ê³¼ í•¨ê»˜ ìƒì„±
                result = generate_korean_content_with_progress(prompt, genre, temperature, max_tokens)
                raw_result = str(result) if result is not None else ""
                st.session_state.result = raw_result
                st.session_state.prompt = prompt
                st.session_state.genre = genre
                st.session_state.timestamp = datetime.now()
            else:
                st.warning("ì°½ì‘ ìš”ì²­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    
    with col2:
        st.subheader("ğŸ“– ì°½ì‘ ê²°ê³¼")
        
        if 'result' in st.session_state:
            # ê²°ê³¼ í‘œì‹œ
            st.markdown("### ìƒì„±ëœ ì‘í’ˆ")
            st.write(st.session_state.result)
            
            # ë©”íƒ€ ì •ë³´
            st.markdown("---")
            col_info1, col_info2, col_info3 = st.columns(3)
            with col_info1:
                st.write(f"**ì¥ë¥´**: {st.session_state.genre}")
            with col_info2:
                st.write(f"**ìƒì„± ì‹œê°„**: {st.session_state.timestamp.strftime('%H:%M:%S')}")
            with col_info3:
                word_count = len(str(st.session_state.result or "").replace(' ', ''))
                st.write(f"**ê¸€ì ìˆ˜**: {word_count:,}ì")
            
            # ì•¡ì…˜ ë²„íŠ¼ë“¤
            st.markdown("---")
            col_btn1, col_btn2, col_btn3 = st.columns(3)
            
            with col_btn1:
                if st.button("ğŸ“‹ ë³µì‚¬í•˜ê¸°"):
                    st.write("í…ìŠ¤íŠ¸ë¥¼ ì„ íƒí•´ì„œ ë³µì‚¬í•˜ì„¸ìš”!")
            
            with col_btn2:
                if st.button("ğŸ’¾ ë‹¤ìš´ë¡œë“œ"):
                    filename = f"{st.session_state.genre}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
                    st.download_button(
                        label="TXT íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=str(st.session_state.result or ""),
                        file_name=filename,
                        mime="text/plain"
                    )
            
            with col_btn3:
                if st.button("â• ì´ì–´ì“°ê¸°"):
                    continue_prompt = f"ë‹¤ìŒ ë‚´ìš©ì„ ì´ì–´ì„œ ì¨ì£¼ì„¸ìš”:\n\n{st.session_state.result}\n\nê³„ì†:"
                    with st.spinner("ì´ì–´ì“°ê¸° ì¤‘..."):
                        cont_raw = generate_korean_content(continue_prompt, st.session_state.genre, temperature, max_tokens)
                        continued = str(cont_raw) if cont_raw is not None else ""
                        st.session_state.result = (st.session_state.result or "") + "\n\n" + continued
                        st.rerun()
        
        else:
            st.info("ì™¼ìª½ì—ì„œ ì°½ì‘ ìš”ì²­ì„ ì…ë ¥í•˜ê³  'ì°½ì‘í•˜ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”!")
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>ğŸ”¥ <strong>30ë¶„ ë§Œì— ë§Œë“  í˜„ì‹¤ì ì¸ í•œêµ­ì–´ AI</strong> ğŸ”¥</p>
        <p>ê³¼ì—”ì§€ë‹ˆì–´ë§ ì—†ì´ ë°”ë¡œ ì¨ë¨¹ì„ ìˆ˜ ìˆëŠ” ì‹¤ìš©ì  ë„êµ¬</p>
        <p><em>"Done is better than perfect" - Mark Zuckerberg</em></p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main() 