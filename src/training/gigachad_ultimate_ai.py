import streamlit as st
import openai
import os
import json
import random
import time
import threading
from datetime import datetime
import uuid
from pathlib import Path
from typing import TypedDict, Literal, Any, cast

# --- Type Definitions ---

class VLSampleNovel(TypedDict):
    title: str
    genre: list[str]
    concept: str
    conflict: str
    structure: str
    motif: str

class VLSampleAnime(TypedDict):
    title: str
    text: list[str]

class VLSamples(TypedDict):
    novel: list[VLSampleNovel]
    anime: list[VLSampleAnime]
    movie: list[dict[str, object]]  # movie structure is not fully clear

class ConversationMessage(TypedDict):
    speaker: str
    content: str

JobStatus = Literal["created", "running", "completed", "error"]

class Job(TypedDict):
    id: str
    user_request: str
    genre: str
    style: str
    advanced_prompt: str
    temperature: float
    max_tokens: int
    status: JobStatus
    progress: float
    result: str | None
    error: str | None
    created_at: datetime
    updated_at: datetime

class DatasetCache(TypedDict):
    patterns_loaded: bool
    vl_samples: VLSamples
    conv_samples: list[list[ConversationMessage]]


# --- API Key Setup ---

api_key = os.getenv("OPEN_API_KEY") or os.getenv("OPENAI_API_KEY")
if api_key:
    openai.api_key = api_key
    openai_available = True
else:
    openai_available = False


# --- Global State Initialization ---

if "jobs" not in st.session_state:
    st.session_state.jobs = {}
if "dataset_cache" not in st.session_state:
    st.session_state.dataset_cache = {}


class DatasetAnalyzer:
    """ë°ì´í„°ì…‹ ë¶„ì„ ë° íŒ¨í„´ ì¶”ì¶œ"""

    def __init__(self) -> None:
        self.base_path: Path = Path("dataset")
        self.vl_novel_path: Path = self.base_path / "VL_novel"
        self.vl_anime_path: Path = self.base_path / "VL_anime"
        self.vl_movie_path: Path = self.base_path / "VL_movie"
        self.daily_path: Path = self.base_path / "daily_json" / "kakao"

    def load_vl_samples(self, count: int = 5) -> VLSamples:
        """VL ë°ì´í„°ì…‹ ìƒ˜í”Œ ë¡œë“œ"""
        samples: VLSamples = {"novel": [], "anime": [], "movie": []}

        # ì†Œì„¤ ìƒ˜í”Œ
        if self.vl_novel_path.exists():
            novel_files = list(self.vl_novel_path.glob("*.json"))[:count]
            for file in novel_files:
                try:
                    with open(file, "r", encoding="utf-8") as f:
                        data = cast(dict[str, Any], json.load(f))
                        novel_sample: VLSampleNovel = {
                            "title": data.get("title", ""),
                            "genre": data.get("genre", []),
                            "concept": data.get("concept", ""),
                            "conflict": data.get("conflict", ""),
                            "structure": data.get("structure", ""),
                            "motif": data.get("motif", ""),
                        }
                        samples["novel"].append(novel_sample)
                except (json.JSONDecodeError, IOError):
                    continue

        # ì• ë‹ˆë©”ì´ì…˜ ìƒ˜í”Œ
        if self.vl_anime_path.exists():
            anime_files = list(self.vl_anime_path.glob("*.json"))[:count]
            for file in anime_files:
                try:
                    with open(file, "r", encoding="utf-8") as f:
                        data = cast(dict[str, Any], json.load(f))
                        anime_sample: VLSampleAnime = {
                            "title": data.get("title", ""),
                            "text": data.get("text", [])[:10],  # ì²˜ìŒ 10ê°œ ì¥ë©´ë§Œ
                        }
                        samples["anime"].append(anime_sample)
                except (json.JSONDecodeError, IOError):
                    continue
        
        # ì˜í™” ìƒ˜í”Œ (êµ¬ì¡°ê°€ ë¶ˆë¶„ëª…í•˜ì—¬ ì¼ë‹¨ ê·¸ëŒ€ë¡œ ë‘ )
        if self.vl_movie_path.exists():
            movie_files = list(self.vl_movie_path.glob("*.json"))[:count]
            for file in movie_files:
                try:
                    with open(file, "r", encoding="utf-8") as f:
                        data = cast(dict[str, object], json.load(f))
                        samples["movie"].append(data)
                except (json.JSONDecodeError, IOError):
                    continue

        return samples

    def load_conversation_samples(self, count: int = 10) -> list[list[ConversationMessage]]:
        """ì¼ìƒ ëŒ€í™” ìƒ˜í”Œ ë¡œë“œ"""
        samples: list[list[ConversationMessage]] = []

        if self.daily_path.exists():
            conv_files = list(self.daily_path.glob("*.json"))[:count]
            for file in conv_files:
                try:
                    with open(file, "r", encoding="utf-8") as f:
                        data = cast(dict[str, Any], json.load(f))
                        messages = data.get("messages", [])
                        if len(messages) >= 4:  # ìµœì†Œ 4ê°œ ë©”ì‹œì§€
                            conversation: list[ConversationMessage] = []
                            for msg in messages[:10]:  # ìµœëŒ€ 10ê°œ
                                conversation.append(
                                    {
                                        "speaker": msg.get("speaker_id", ""),
                                        "content": msg.get("content", ""),
                                    }
                                )
                            samples.append(conversation)
                except (json.JSONDecodeError, IOError):
                    continue

        return samples


class GigaChadAI:
    """ì´ˆê³ ì„±ëŠ¥ í•œêµ­ì–´ ì°½ì‘ AI"""

    def __init__(self) -> None:
        self.jobs: dict[str, Job] = st.session_state.jobs
        self.analyzer: DatasetAnalyzer = DatasetAnalyzer()
        self.vl_samples: VLSamples
        self.conv_samples: list[list[ConversationMessage]]
        self.load_dataset_patterns()

    def load_dataset_patterns(self) -> None:
        """ë°ì´í„°ì…‹ íŒ¨í„´ ë¡œë“œ (ìºì‹œ í™œìš©)"""
        cache: DatasetCache = st.session_state.dataset_cache
        if "patterns_loaded" not in cache:
            with st.spinner("ğŸ“š ê³ ê¸‰ ì°½ì‘ íŒ¨í„´ ë¡œë”© ì¤‘..."):
                self.vl_samples = self.analyzer.load_vl_samples()
                self.conv_samples = self.analyzer.load_conversation_samples()
                cache["vl_samples"] = self.vl_samples
                cache["conv_samples"] = self.conv_samples
                cache["patterns_loaded"] = True
        else:
            self.vl_samples = cache["vl_samples"]
            self.conv_samples = cache["conv_samples"]

    def generate_advanced_prompt(self, user_request: str, genre: str, style: str = "ì†Œì„¤") -> str:
        """ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ìƒì„± - ë°ì´í„°ì…‹ íŒ¨í„´ í™œìš©"""

        # VL ë°ì´í„°ì…‹ì—ì„œ ê´€ë ¨ íŒ¨í„´ ì¶”ì¶œ
        relevant_samples: list[VLSampleNovel | VLSampleAnime] = []
        if style == "ì†Œì„¤" and self.vl_samples["novel"]:
            for sample in self.vl_samples["novel"]:
                if any(g in sample["genre"] for g in [genre, "ë“œë¼ë§ˆ"]):
                    relevant_samples.append(sample)

        # ì• ë‹ˆë©”ì´ì…˜ ìŠ¤íƒ€ì¼ ìš”ì²­ì‹œ
        elif style == "ì• ë‹ˆë©”ì´ì…˜" and self.vl_samples["anime"]:
            relevant_samples.extend(self.vl_samples["anime"][:2])

        # ëŒ€í™”ì²´ ìš”ì²­ì‹œ
        conversation_example = ""
        if "ëŒ€í™”" in user_request or "ëŒ€ì‚¬" in user_request:
            if self.conv_samples:
                sample_conv = random.choice(self.conv_samples)
                conversation_example = (
                    "ëŒ€í™” ì˜ˆì‹œ ì°¸ê³ :\n"
                    + "\n".join([f"í™”ì{msg['speaker']}: {msg['content']}" for msg in sample_conv[:4]])
                )

        # êµ¬ì¡° íŒ¨í„´ ì¶”ì¶œ
        structure_guide = ""
        if relevant_samples:
            sample = relevant_samples[0]
            if style == "ì†Œì„¤":
                novel_sample = cast(VLSampleNovel, sample)
                structure_guide = f"""
ì°¸ê³  êµ¬ì¡°:
- ê°ˆë“±: {novel_sample.get('conflict', '')[:100]}...
- ëª¨í‹°í”„: {novel_sample.get('motif', '')}
- ì»¨ì…‰: {novel_sample.get('concept', '')[:100]}...
"""

        # ì¥ë¥´ë³„ íŠ¹í™” ì§€ì¹¨
        genre_guides = {
            "íŒíƒ€ì§€": """
íŒíƒ€ì§€ ì°½ì‘ ì§€ì¹¨:
- ë…ì°½ì ì¸ ë§ˆë²• ì‹œìŠ¤í…œì´ë‚˜ ì„¸ê³„ê´€ ì„¤ì •
- í´ë¦¬ì…° íƒˆí”¼: ì „í˜•ì ì¸ "ì„ íƒë°›ì€ ì" ì„œì‚¬ ì§€ì–‘
- í•œêµ­ì  ì •ì„œì™€ ì„œêµ¬ íŒíƒ€ì§€ì˜ ì¡°í™”
- êµ¬ì²´ì ì¸ ë§ˆë²• ì›ë¦¬ì™€ ì œì•½ ì„¤ì •
- ìºë¦­í„°ë³„ ëª…í™•í•œ ë™ê¸°ì™€ ì„±ì¥ ì•„í¬
""",
            "ë¡œë§¨ìŠ¤": """
ë¡œë§¨ìŠ¤ ì°½ì‘ ì§€ì¹¨:
- í˜„ì‹¤ì ì´ë©´ì„œë„ ê°ë™ì ì¸ ë§Œë‚¨ê³¼ ê°ˆë“±
- í•œêµ­ì  ì—°ì•  ë¬¸í™”ì™€ í˜„ëŒ€ì  ê°€ì¹˜ê´€ ë°˜ì˜
- ë‹¨ìˆœí•œ ì™¸ëª¨ ëŒë¦¼ë³´ë‹¤ ë‚´ì  ì„±ì¥ì„ í†µí•œ ì‚¬ë‘
- êµ¬ì²´ì ì¸ ê°ì • ë³€í™” ê³¼ì • ë¬˜ì‚¬
- ì†Œí†µê³¼ ì˜¤í•´, í™”í•´ì˜ í˜„ì‹¤ì  ê³¼ì •
""",
            "SF": """
SF ì°½ì‘ ì§€ì¹¨:
- ê³¼í•™ì  ê°œë…ì˜ í•œêµ­ì  í•´ì„ê³¼ ì‚¬íšŒ ë¹„íŒ
- ê¸°ìˆ  ë°œì „ì´ ì¸ê°„ê´€ê³„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
- í˜„ì¬ í•œêµ­ ì‚¬íšŒ ë¬¸ì œì˜ ë¯¸ë˜ì  íˆ¬ì˜
- ë‹¨ìˆœí•œ ê¸°ìˆ  ê³¼ì‹œë³´ë‹¤ ì¸ê°„ì„± íƒêµ¬
- ë…¼ë¦¬ì  ì„¤ì •ê³¼ ê°ì •ì  ëª°ì…ì˜ ê· í˜•
""",
            "ë¯¸ìŠ¤í„°ë¦¬": """
ë¯¸ìŠ¤í„°ë¦¬ ì°½ì‘ ì§€ì¹¨:
- í•œêµ­ ì‚¬íšŒ í˜„ì‹¤ì„ ë°˜ì˜í•œ ì‚¬ê±´ê³¼ ë™ê¸°
- ì¹˜ë°€í•œ ë‹¨ì„œ ë°°ì¹˜ì™€ ë…¼ë¦¬ì  ì¶”ë¦¬ ê³¼ì •
- ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë²”ì¸ë³´ë‹¤ ì˜ì™¸ì„± ìˆëŠ” ë°˜ì „
- ì‚¬íšŒì  ë©”ì‹œì§€ë¥¼ ë‹´ì€ ì‚¬ê±´ ë°°ê²½
- ë…ìì˜ ì¶”ë¦¬ ì°¸ì—¬ë¥¼ ìœ ë„í•˜ëŠ” êµ¬ì¡°
""",
            "ë“œë¼ë§ˆ": """
ë“œë¼ë§ˆ ì°½ì‘ ì§€ì¹¨:
- ì¼ìƒì ì´ì§€ë§Œ íŠ¹ë³„í•œ ìˆœê°„ë“¤ì˜ í¬ì°©
- í•œêµ­ ê°€ì¡± ë¬¸í™”ì™€ ì„¸ëŒ€ ê°ˆë“± ë°˜ì˜
- í‰ë²”í•œ ì¸ë¬¼ë“¤ì˜ ë¹„ë²”í•œ ì„±ì¥ ì´ì•¼ê¸°
- í˜„ì‹¤ì  ê°ˆë“±ê³¼ ë”°ëœ»í•œ í•´ê²° ê³¼ì •
- ë…ì ê³µê°ì„ ì´ë„ëŠ” ë³´í¸ì  ê°ì •
""",
        }

        advanced_prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ìµœê³  ìˆ˜ì¤€ì˜ ì°½ì‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

{genre_guides.get(genre, "")}

{structure_guide}

{conversation_example}

íŠ¹ë³„ ì§€ì¹¨:
1. í´ë¦¬ì…° ì™„ì „ íƒˆí”¼ - ë»”í•œ ì„¤ì •ê³¼ ì „ê°œ ê¸ˆì§€
2. ìºë¦­í„° ê°œì„± ê°•í™” - ê°ìë§Œì˜ ë…íŠ¹í•œ íŠ¹ì§•ê³¼ ë§íˆ¬
3. ê°ˆë“± êµ¬ì¡° ë³µì¡í™” - ë‹¨ìˆœí•œ ì„ ì•… êµ¬ì¡° ì§€ì–‘
4. ê°ì • ë¬˜ì‚¬ êµ¬ì²´í™” - ìƒí™© ì„¤ëª…ë³´ë‹¤ ë‚´ë©´ ë¬˜ì‚¬ ì¤‘ì‹¬
5. í•œêµ­ì  ì •ì„œ - ë¬¸í™”ì™€ ì–¸ì–´ì˜ ìì—°ìŠ¤ëŸ¬ìš´ í™œìš©

ì‚¬ìš©ì ìš”ì²­: {user_request}

ìœ„ ì§€ì¹¨ì„ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ ê³ í’ˆì§ˆì˜ {genre} {style}ì„ ì°½ì‘í•´ì£¼ì„¸ìš”.
ê¸€ì ìˆ˜ ì œí•œ ì—†ì´ ì¶©ë¶„íˆ ìƒì„¸í•˜ê³  ëª°ì…ê° ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”."""

        return advanced_prompt

    def create_job(
        self, user_request: str, genre: str, style: str = "ì†Œì„¤", temperature: float = 0.8, max_tokens: int = 2000
    ) -> str:
        """ê³ ê¸‰ ì‘ì—… ìƒì„±"""
        job_id = str(uuid.uuid4())[:8]

        # ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ìƒì„±
        advanced_prompt = self.generate_advanced_prompt(user_request, genre, style)

        job: Job = {
            "id": job_id,
            "user_request": user_request,
            "genre": genre,
            "style": style,
            "advanced_prompt": advanced_prompt,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "status": "created",
            "progress": 0.0,
            "result": None,
            "error": None,
            "created_at": datetime.now(),
            "updated_at": datetime.now(),
        }
        self.jobs[job_id] = job

        return job_id

    def update_job(self, job_id: str, **kwargs: object) -> None:
        """ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if job_id in self.jobs:
            job_to_update = self.jobs[job_id]
            for key, value in kwargs.items():
                if key in Job.__annotations__:
                    cast(dict[str, object], cast(object, job_to_update))[key] = value
            job_to_update["updated_at"] = datetime.now()

    def process_job_background(self, job_id: str) -> None:
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ AI ì‘ì—… ì²˜ë¦¬"""
        try:
            job = self.jobs[job_id]
            self.update_job(job_id, status="running")

            # Streaming ì‘ë‹µ ì²˜ë¦¬
            full_response = ""
            if not openai_available:
                raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

            stream = openai.chat.completions.create(
                model="gpt-4-turbo",
                messages=[
                    {"role": "system", "content": "You are a creative writing expert."},
                    {"role": "user", "content": job["advanced_prompt"]},
                ],
                max_tokens=job["max_tokens"],
                temperature=job["temperature"],
                stream=True,
            )

            chunk_count = 0
            for chunk in stream:
                chunk_count += 1
                content = chunk.choices[0].delta.content
                if content:
                    full_response += content
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ì˜ˆì‹œ: 200 ì²­í¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ)
                    progress = min(chunk_count / 200, 0.9)
                    self.update_job(job_id, progress=progress, result=full_response)
                time.sleep(0.02)  # UI ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ì•½ê°„ì˜ ì§€ì—°

            self.update_job(job_id, status="completed", progress=1.0, result=full_response)

        except Exception as e:
            error_message = f"ì‘ì—… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
            self.update_job(job_id, status="error", error=error_message, progress=1.0)

    def start_job(self, job_id: str) -> threading.Thread:
        """ì‘ì—… ìŠ¤ë ˆë“œ ì‹œì‘"""
        thread = threading.Thread(target=self.process_job_background, args=(job_id,))
        thread.daemon = True
        thread.start()
        return thread


def main() -> None:
    """Streamlit UI ë©”ì¸ í•¨ìˆ˜"""
    _ = st.set_page_config(page_title="ê¸°ê°€ì°¨ë“œ AI", layout="wide")
    _ = st.title("ğŸ”¥ ê¸°ê°€ì°¨ë“œ AI: ì´ˆê³ ì„±ëŠ¥ í•œêµ­ì–´ ìŠ¤í† ë¦¬ ìƒì„±ê¸°")
    _ = st.caption(f"OpenAI API ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if openai_available else 'âŒ'}")

    if "ai" not in st.session_state:
        st.session_state.ai = GigaChadAI()
    ai: GigaChadAI = st.session_state.ai

    tab1, tab2, tab3 = st.tabs(["ğŸ’¡ ìƒˆ ìŠ¤í† ë¦¬ ìƒì„±", "â³ ì‘ì—… í˜„í™©", "ğŸ“š ë°ì´í„°ì…‹ ë¶„ì„"])

    with tab1:
        _ = st.header("ìƒˆë¡œìš´ ìŠ¤í† ë¦¬ ì•„ì´ë””ì–´ êµ¬ìƒ")
        col1, col2 = st.columns(2)

        with col1:
            _ = st.subheader("1. ê¸°ë³¸ ì„¤ì •")
            user_request = st.text_area(
                "ì–´ë–¤ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
                height=150,
                placeholder="ì˜ˆ: ìš°ì£¼ë¥¼ ì—¬í–‰í•˜ëŠ” ê³ ì–‘ì´ì˜ ì´ì•¼ê¸°",
            )
            genre = st.selectbox(
                "ì¥ë¥´ë¥¼ ì„ íƒí•˜ì„¸ìš”.",
                ["íŒíƒ€ì§€", "ë¡œë§¨ìŠ¤", "SF", "ë¯¸ìŠ¤í„°ë¦¬", "ë“œë¼ë§ˆ"],
            )
            style = st.radio("ìŠ¤íƒ€ì¼", ["ì†Œì„¤", "ì• ë‹ˆë©”ì´ì…˜", "ëŒ€í™”ì²´ ì‹œë‚˜ë¦¬ì˜¤"])

        with col2:
            _ = st.subheader("2. ê³ ê¸‰ ì„¤ì •")
            temperature = st.slider("ì°½ì˜ì„± (Temperature)", 0.1, 1.0, 0.8, 0.05)
            max_tokens = st.slider("ìµœëŒ€ ê¸¸ì´ (Max Tokens)", 500, 4000, 2000, 100)

            if st.button("ğŸš€ ê¸°ê°€ì°¨ë“œ! ìŠ¤í† ë¦¬ ìƒì„± ì‹œì‘!", type="primary", use_container_width=True):
                if user_request and genre and openai_available:
                    with st.spinner("ê¸°ê°€ì°¨ë“œê°€ ì‘ì—…ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
                        job_id = ai.create_job(
                            user_request,
                            genre,
                            style,
                            temperature=temperature,
                            max_tokens=max_tokens,
                        )
                        _ = ai.start_job(job_id)
                        _ = st.success(f"ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤! (ID: {job_id}) 'ì‘ì—… í˜„í™©' íƒ­ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
                        _ = st.balloons()
                elif not openai_available:
                    _ = st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
                else:
                    _ = st.warning("ì´ì•¼ê¸° ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    with tab2:
        _ = st.header("ì‘ì—… ì§„í–‰ í˜„í™©")
        if not ai.jobs:
            _ = st.info("ì•„ì§ ìƒì„±ëœ ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤. 'ìƒˆ ìŠ¤í† ë¦¬ ìƒì„±' íƒ­ì—ì„œ ìƒˆ ì‘ì—…ì„ ì‹œì‘í•˜ì„¸ìš”.")
        else:
            # ì‘ì—…ì„ ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_jobs: list[Job] = sorted(
                ai.jobs.values(), key=lambda j: j["created_at"], reverse=True
            )

            for job in sorted_jobs:
                with st.expander(
                    f"**{job['id']}**: {job['user_request'][:30]}... ({job['status']})",
                    expanded=job["status"] in ["running", "created"],
                ):
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        _ = st.metric("ì¥ë¥´", job["genre"])
                    with col2:
                        _ = st.metric("ìŠ¤íƒ€ì¼", job["style"])
                    with col3:
                        created_time = job["created_at"].strftime("%Y-%m-%d %H:%M:%S")
                        _ = st.metric("ìƒì„± ì‹œê°", created_time)

                    _ = st.progress(job["progress"], text=f"ì§„í–‰ë¥ : {job['progress']:.0%}")

                    if job["status"] == "running":
                        _ = st.info("ê¸°ê°€ì°¨ë“œê°€ ìŠ¤í† ë¦¬ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
                    elif job["status"] == "completed":
                        _ = st.success("ì‘ì—… ì™„ë£Œ!")
                    elif job["status"] == "error":
                        _ = st.error(f"ì˜¤ë¥˜ ë°œìƒ: {job['error']}")

                    if job["result"]:
                        _ = st.subheader("ê²°ê³¼ë¬¼")
                        _ = st.text_area(
                            "ìƒì„±ëœ ìŠ¤í† ë¦¬",
                            value=job["result"],
                            height=300,
                            key=f"result_{job['id']}",
                        )
                        result_bytes = job["result"].encode("utf-8")
                        _ = st.download_button(
                            label="ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                            data=result_bytes,
                            file_name=f"gigachad_story_{job['id']}.txt",
                            mime="text/plain",
                        )
                    if job["status"] == "created":
                        if st.button("ì‘ì—… ì¬ì‹œì‘", key=f"restart_{job['id']}"):
                            _ = ai.start_job(job['id'])
                            _ = st.rerun()


    with tab3:
        _ = st.header("ë°ì´í„°ì…‹ íŒ¨í„´ ë¶„ì„")
        _ = st.info("ê¸°ê°€ì°¨ë“œ AIëŠ” ì•„ë˜ì™€ ê°™ì€ ë°ì´í„° íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ë” ë‚˜ì€ ê²°ê³¼ë¬¼ì„ ìƒì„±í•©ë‹ˆë‹¤.")

        with st.expander("VL (Vess-AI-Verse) ì†Œì„¤ ë°ì´í„°ì…‹ ìƒ˜í”Œ"):
            if ai.vl_samples["novel"]:
                for sample in ai.vl_samples["novel"]:
                    _ = st.write(f"##### {sample['title']}")
                    _ = st.json(sample, expanded=False)
            else:
                _ = st.write("ì†Œì„¤ ìƒ˜í”Œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        with st.expander("VL (Vess-AI-Verse) ì• ë‹ˆë©”ì´ì…˜ ë°ì´í„°ì…‹ ìƒ˜í”Œ"):
            if ai.vl_samples["anime"]:
                for sample in ai.vl_samples["anime"]:
                    _ = st.write(f"##### {sample['title']}")
                    _ = st.json(sample, expanded=False)
            else:
                _ = st.write("ì• ë‹ˆë©”ì´ì…˜ ìƒ˜í”Œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        with st.expander("ì¼ìƒ ëŒ€í™” ë°ì´í„°ì…‹ ìƒ˜í”Œ"):
            if ai.conv_samples:
                for sample in ai.conv_samples:
                    _ = st.json(sample, expanded=False)
            else:
                _ = st.write("ëŒ€í™” ìƒ˜í”Œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
