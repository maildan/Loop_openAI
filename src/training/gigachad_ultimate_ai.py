import streamlit as st
import openai
import os
import json
import random
import time
import threading
from datetime import datetime
import uuid
from pathlib import Path

# API í‚¤ ì„¤ì •
api_key = os.getenv("OPEN_API_KEY") or os.getenv("OPENAI_API_KEY")
if api_key:
    openai.api_key = api_key

# ì „ì—­ ì‘ì—… ìƒíƒœ ì €ì¥ì†Œ
if 'jobs' not in st.session_state:
    st.session_state.jobs = {}
if 'dataset_cache' not in st.session_state:
    st.session_state.dataset_cache = {}

class DatasetAnalyzer:
    """ë°ì´í„°ì…‹ ë¶„ì„ ë° íŒ¨í„´ ì¶”ì¶œ"""
    
    def __init__(self):
        self.base_path = Path("dataset")
        self.vl_novel_path = self.base_path / "VL_novel"
        self.vl_anime_path = self.base_path / "VL_anime" 
        self.vl_movie_path = self.base_path / "VL_movie"
        self.daily_path = self.base_path / "daily_json" / "kakao"
        
    def load_vl_samples(self, count=5):
        """VL ë°ì´í„°ì…‹ ìƒ˜í”Œ ë¡œë“œ"""
        samples = {'novel': [], 'anime': [], 'movie': []}
        
        # ì†Œì„¤ ìƒ˜í”Œ
        if self.vl_novel_path.exists():
            novel_files = list(self.vl_novel_path.glob("*.json"))[:count]
            for file in novel_files:
                try:
                    with open(file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        samples['novel'].append({
                            'title': data.get('title', ''),
                            'genre': data.get('genre', []),
                            'concept': data.get('concept', ''),
                            'conflict': data.get('conflict', ''),
                            'structure': data.get('structure', ''),
                            'motif': data.get('motif', '')
                        })
                except:
                    continue
        
        # ì• ë‹ˆë©”ì´ì…˜ ìƒ˜í”Œ
        if self.vl_anime_path.exists():
            anime_files = list(self.vl_anime_path.glob("*.json"))[:count]
            for file in anime_files:
                try:
                    with open(file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        samples['anime'].append({
                            'title': data.get('title', ''),
                            'text': data.get('text', [])[:10]  # ì²˜ìŒ 10ê°œ ì¥ë©´ë§Œ
                        })
                except:
                    continue
                    
        return samples
    
    def load_conversation_samples(self, count=10):
        """ì¼ìƒ ëŒ€í™” ìƒ˜í”Œ ë¡œë“œ"""
        samples = []
        
        if self.daily_path.exists():
            conv_files = list(self.daily_path.glob("*.json"))[:count]
            for file in conv_files:
                try:
                    with open(file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        messages = data.get('messages', [])
                        if len(messages) >= 4:  # ìµœì†Œ 4ê°œ ë©”ì‹œì§€
                            conversation = []
                            for msg in messages[:10]:  # ìµœëŒ€ 10ê°œ
                                conversation.append({
                                    'speaker': msg.get('speaker_id', ''),
                                    'content': msg.get('content', '')
                                })
                            samples.append(conversation)
                except:
                    continue
                    
        return samples

class GigaChadAI:
    """ì´ˆê³ ì„±ëŠ¥ í•œêµ­ì–´ ì°½ì‘ AI"""
    
    def __init__(self):
        self.jobs = st.session_state.jobs
        self.analyzer = DatasetAnalyzer()
        self.load_dataset_patterns()
    
    def load_dataset_patterns(self):
        """ë°ì´í„°ì…‹ íŒ¨í„´ ë¡œë“œ (ìºì‹œ í™œìš©)"""
        if 'patterns_loaded' not in st.session_state.dataset_cache:
            with st.spinner("ğŸ“š ê³ ê¸‰ ì°½ì‘ íŒ¨í„´ ë¡œë”© ì¤‘..."):
                self.vl_samples = self.analyzer.load_vl_samples()
                self.conv_samples = self.analyzer.load_conversation_samples()
                st.session_state.dataset_cache['vl_samples'] = self.vl_samples
                st.session_state.dataset_cache['conv_samples'] = self.conv_samples
                st.session_state.dataset_cache['patterns_loaded'] = True
        else:
            self.vl_samples = st.session_state.dataset_cache['vl_samples']
            self.conv_samples = st.session_state.dataset_cache['conv_samples']
    
    def generate_advanced_prompt(self, user_request, genre, style="ì†Œì„¤"):
        """ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ìƒì„± - ë°ì´í„°ì…‹ íŒ¨í„´ í™œìš©"""
        
        # VL ë°ì´í„°ì…‹ì—ì„œ ê´€ë ¨ íŒ¨í„´ ì¶”ì¶œ
        relevant_samples = []
        if style == "ì†Œì„¤" and self.vl_samples['novel']:
            for sample in self.vl_samples['novel']:
                if any(g in sample['genre'] for g in [genre, 'ë“œë¼ë§ˆ']):
                    relevant_samples.append(sample)
        
        # ì• ë‹ˆë©”ì´ì…˜ ìŠ¤íƒ€ì¼ ìš”ì²­ì‹œ
        if style == "ì• ë‹ˆë©”ì´ì…˜" and self.vl_samples['anime']:
            relevant_samples = self.vl_samples['anime'][:2]
        
        # ëŒ€í™”ì²´ ìš”ì²­ì‹œ
        conversation_example = ""
        if "ëŒ€í™”" in user_request or "ëŒ€ì‚¬" in user_request:
            if self.conv_samples:
                sample_conv = random.choice(self.conv_samples)
                conversation_example = f"""
ëŒ€í™” ì˜ˆì‹œ ì°¸ê³ :
{chr(10).join([f"í™”ì{msg['speaker']}: {msg['content']}" for msg in sample_conv[:4]])}
"""

        # êµ¬ì¡° íŒ¨í„´ ì¶”ì¶œ
        structure_guide = ""
        if relevant_samples:
            sample = relevant_samples[0]
            structure_guide = f"""
ì°¸ê³  êµ¬ì¡°:
- ê°ˆë“±: {sample.get('conflict', '')[:100]}...
- ëª¨í‹°í”„: {sample.get('motif', '')}
- ì»¨ì…‰: {sample.get('concept', '')[:100]}...
"""

        # ì¥ë¥´ë³„ íŠ¹í™” ì§€ì¹¨
        genre_guides = {
            "íŒíƒ€ì§€": """
íŒíƒ€ì§€ ì°½ì‘ ì§€ì¹¨:
- ë…ì°½ì ì¸ ë§ˆë²• ì‹œìŠ¤í…œì´ë‚˜ ì„¸ê³„ê´€ ì„¤ì •
- í´ë¦¬ì…° íƒˆí”¼: ì „í˜•ì ì¸ "ì„ íƒë°›ì€ ì" ì„œì‚¬ ì§€ì–‘
- í•œêµ­ì  ì •ì„œì™€ ì„œêµ¬ íŒíƒ€ì§€ì˜ ì¡°í™”
- êµ¬ì²´ì ì¸ ë§ˆë²• ì›ë¦¬ì™€ ì œì•½ ì„¤ì •
- ìºë¦­í„°ë³„ ëª…í™•í•œ ë™ê¸°ì™€ ì„±ì¥ ì•„í¬
""",
            "ë¡œë§¨ìŠ¤": """
ë¡œë§¨ìŠ¤ ì°½ì‘ ì§€ì¹¨:
- í˜„ì‹¤ì ì´ë©´ì„œë„ ê°ë™ì ì¸ ë§Œë‚¨ê³¼ ê°ˆë“±
- í•œêµ­ì  ì—°ì•  ë¬¸í™”ì™€ í˜„ëŒ€ì  ê°€ì¹˜ê´€ ë°˜ì˜
- ë‹¨ìˆœí•œ ì™¸ëª¨ ëŒë¦¼ë³´ë‹¤ ë‚´ì  ì„±ì¥ì„ í†µí•œ ì‚¬ë‘
- êµ¬ì²´ì ì¸ ê°ì • ë³€í™” ê³¼ì • ë¬˜ì‚¬
- ì†Œí†µê³¼ ì˜¤í•´, í™”í•´ì˜ í˜„ì‹¤ì  ê³¼ì •
""",
            "SF": """
SF ì°½ì‘ ì§€ì¹¨:
- ê³¼í•™ì  ê°œë…ì˜ í•œêµ­ì  í•´ì„ê³¼ ì‚¬íšŒ ë¹„íŒ
- ê¸°ìˆ  ë°œì „ì´ ì¸ê°„ê´€ê³„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
- í˜„ì¬ í•œêµ­ ì‚¬íšŒ ë¬¸ì œì˜ ë¯¸ë˜ì  íˆ¬ì˜
- ë‹¨ìˆœí•œ ê¸°ìˆ  ê³¼ì‹œë³´ë‹¤ ì¸ê°„ì„± íƒêµ¬
- ë…¼ë¦¬ì  ì„¤ì •ê³¼ ê°ì •ì  ëª°ì…ì˜ ê· í˜•
""",
            "ë¯¸ìŠ¤í„°ë¦¬": """
ë¯¸ìŠ¤í„°ë¦¬ ì°½ì‘ ì§€ì¹¨:
- í•œêµ­ ì‚¬íšŒ í˜„ì‹¤ì„ ë°˜ì˜í•œ ì‚¬ê±´ê³¼ ë™ê¸°
- ì¹˜ë°€í•œ ë‹¨ì„œ ë°°ì¹˜ì™€ ë…¼ë¦¬ì  ì¶”ë¦¬ ê³¼ì •
- ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë²”ì¸ë³´ë‹¤ ì˜ì™¸ì„± ìˆëŠ” ë°˜ì „
- ì‚¬íšŒì  ë©”ì‹œì§€ë¥¼ ë‹´ì€ ì‚¬ê±´ ë°°ê²½
- ë…ìì˜ ì¶”ë¦¬ ì°¸ì—¬ë¥¼ ìœ ë„í•˜ëŠ” êµ¬ì¡°
""",
            "ë“œë¼ë§ˆ": """
ë“œë¼ë§ˆ ì°½ì‘ ì§€ì¹¨:
- ì¼ìƒì ì´ì§€ë§Œ íŠ¹ë³„í•œ ìˆœê°„ë“¤ì˜ í¬ì°©
- í•œêµ­ ê°€ì¡± ë¬¸í™”ì™€ ì„¸ëŒ€ ê°ˆë“± ë°˜ì˜
- í‰ë²”í•œ ì¸ë¬¼ë“¤ì˜ ë¹„ë²”í•œ ì„±ì¥ ì´ì•¼ê¸°
- í˜„ì‹¤ì  ê°ˆë“±ê³¼ ë”°ëœ»í•œ í•´ê²° ê³¼ì •
- ë…ì ê³µê°ì„ ì´ë„ëŠ” ë³´í¸ì  ê°ì •
"""
        }

        advanced_prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ ìµœê³  ìˆ˜ì¤€ì˜ ì°½ì‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

{genre_guides.get(genre, "")}

{structure_guide}

{conversation_example}

íŠ¹ë³„ ì§€ì¹¨:
1. í´ë¦¬ì…° ì™„ì „ íƒˆí”¼ - ë»”í•œ ì„¤ì •ê³¼ ì „ê°œ ê¸ˆì§€
2. ìºë¦­í„° ê°œì„± ê°•í™” - ê°ìë§Œì˜ ë…íŠ¹í•œ íŠ¹ì§•ê³¼ ë§íˆ¬
3. ê°ˆë“± êµ¬ì¡° ë³µì¡í™” - ë‹¨ìˆœí•œ ì„ ì•… êµ¬ì¡° ì§€ì–‘
4. ê°ì • ë¬˜ì‚¬ êµ¬ì²´í™” - ìƒí™© ì„¤ëª…ë³´ë‹¤ ë‚´ë©´ ë¬˜ì‚¬ ì¤‘ì‹¬
5. í•œêµ­ì  ì •ì„œ - ë¬¸í™”ì™€ ì–¸ì–´ì˜ ìì—°ìŠ¤ëŸ¬ìš´ í™œìš©

ì‚¬ìš©ì ìš”ì²­: {user_request}

ìœ„ ì§€ì¹¨ì„ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ ê³ í’ˆì§ˆì˜ {genre} {style}ì„ ì°½ì‘í•´ì£¼ì„¸ìš”.
ê¸€ì ìˆ˜ ì œí•œ ì—†ì´ ì¶©ë¶„íˆ ìƒì„¸í•˜ê³  ëª°ì…ê° ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”."""

        return advanced_prompt
    
    def create_job(self, user_request, genre, style="ì†Œì„¤", temperature=0.8, max_tokens=2000):
        """ê³ ê¸‰ ì‘ì—… ìƒì„±"""
        job_id = str(uuid.uuid4())[:8]
        
        # ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ìƒì„±
        advanced_prompt = self.generate_advanced_prompt(user_request, genre, style)
        
        self.jobs[job_id] = {
            'id': job_id,
            'user_request': user_request,
            'genre': genre,
            'style': style,
            'advanced_prompt': advanced_prompt,
            'temperature': temperature,
            'max_tokens': max_tokens,
            'status': 'created',
            'progress': 0,
            'result': None,
            'error': None,
            'created_at': datetime.now(),
            'updated_at': datetime.now()
        }
        
        return job_id
    
    def update_job(self, job_id, **kwargs):
        """ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if job_id in self.jobs:
            self.jobs[job_id].update(kwargs)
            self.jobs[job_id]['updated_at'] = datetime.now()
    
    def process_job_background(self, job_id):
        """ë°±ê·¸ë¼ìš´ë“œ ê³ ê¸‰ ì²˜ë¦¬"""
        try:
            job = self.jobs[job_id]
            
            # ë‹¨ê³„ë³„ ì§„í–‰
            self.update_job(job_id, status='processing', progress=10)
            time.sleep(0.3)
            
            self.update_job(job_id, progress=20, status_msg="ğŸ§  ê³ ê¸‰ ì°½ì‘ íŒ¨í„´ ë¶„ì„ ì¤‘...")
            time.sleep(0.5)
            
            self.update_job(job_id, progress=40, status_msg="âœï¸ ì°½ì‘ ì‹œì‘...")
            
            # OpenAI API í˜¸ì¶œ (ìŠ¤íŠ¸ë¦¬ë°)
            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ ìµœê³  ìˆ˜ì¤€ì˜ ì°½ì‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": job['advanced_prompt']}
                ],
                max_tokens=job['max_tokens'],
                temperature=job['temperature'],
                stream=True
            )
            
            self.update_job(job_id, progress=60, status_msg="ğŸ“ ê³ í’ˆì§ˆ í…ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
            
            # ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ ìˆ˜ì§‘
            full_response = ""
            chunk_count = 0
            for chunk in response:
                if chunk.choices[0].delta.content:
                    full_response += chunk.choices[0].delta.content
                    chunk_count += 1
                    
                    # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸ (60-95%)
                    if chunk_count % 10 == 0:
                        progress = min(95, 60 + (len(full_response) // 50))
                        self.update_job(job_id, progress=progress)
            
            self.update_job(job_id, progress=98, status_msg="ğŸ¨ ìµœì¢… í’ˆì§ˆ ê²€í† ...")
            time.sleep(0.5)
            
            # ì™„ë£Œ
            self.update_job(job_id, 
                          status='completed', 
                          progress=100, 
                          result=full_response,
                          status_msg="ğŸ‰ ì°½ì‘ ì™„ë£Œ!")
            
        except Exception as e:
            self.update_job(job_id, 
                          status='error', 
                          error=f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def start_job(self, job_id):
        """ì‘ì—… ì‹œì‘"""
        thread = threading.Thread(target=self.process_job_background, args=(job_id,))
        thread.daemon = True
        thread.start()
        return thread

def main():
    st.set_page_config(
        page_title="ğŸ”¥ ê¸°ê°€ì°¨ë“œ ê¶ê·¹ AI",
        page_icon="âš¡",
        layout="wide"
    )
    
    # í—¤ë”
    st.title("ğŸ”¥ ê¸°ê°€ì°¨ë“œ ê¶ê·¹ í•œêµ­ì–´ ì°½ì‘ AI")
    st.markdown("**14,024ê°œ ë°ì´í„°ì…‹ í•™ìŠµ â€¢ ë¬´ì œí•œ ê¸¸ì´ â€¢ ì´ˆê³ í’ˆì§ˆ** âš¡")
    
    if not api_key:
        st.error("âŒ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤! í™˜ê²½ë³€ìˆ˜ OPEN_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return
    
    ai = GigaChadAI()
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ê³ ê¸‰ ì„¤ì •")
        
        # ê¸°ë³¸ ì„¤ì •
        genre = st.selectbox(
            "ì¥ë¥´ ì„ íƒ",
            ["íŒíƒ€ì§€", "ë¡œë§¨ìŠ¤", "SF", "ë¯¸ìŠ¤í„°ë¦¬", "ë“œë¼ë§ˆ"],
            help="14,024ê°œ ë°ì´í„°ì…‹ ê¸°ë°˜ ì¥ë¥´ë³„ íŠ¹í™”"
        )
        
        style = st.selectbox(
            "ìŠ¤íƒ€ì¼",
            ["ì†Œì„¤", "ì‹œë‚˜ë¦¬ì˜¤", "ì• ë‹ˆë©”ì´ì…˜", "ì›¹íˆ°", "ë“œë¼ë§ˆ ëŒ€ë³¸"],
            help="VL ë°ì´í„°ì…‹ íŒ¨í„´ ì ìš©"
        )
        
        # ê³ ê¸‰ ì„¤ì •
        st.subheader("ğŸ›ï¸ ì°½ì‘ íŒŒë¼ë¯¸í„°")
        temperature = st.slider("ì°½ì˜ì„±", 0.1, 1.0, 0.8, 0.1, 
                               help="ë†’ì„ìˆ˜ë¡ ì°½ì˜ì , ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì ")
        max_tokens = st.slider("ìµœëŒ€ ê¸¸ì´", 1000, 4000, 2000, 500,
                              help="ê¸€ì ìˆ˜ ì œí•œ ì—†ìŒ ëª¨ë“œ")
        
        # ë°ì´í„°ì…‹ ì •ë³´
        st.markdown("---")
        st.subheader("ğŸ“Š í•™ìŠµ ë°ì´í„°")
        
        col_a, col_b = st.columns(2)
        with col_a:
            st.metric("VL ì°½ì‘", "3,062ê°œ")
            st.metric("ì¼ìƒ ëŒ€í™”", "10,962ê°œ")
        with col_b:
            st.metric("ì´ ë°ì´í„°", "14,024ê°œ")
            st.metric("í’ˆì§ˆ ë“±ê¸‰", "A+")
        
        # ì‘ì—… í˜„í™©
        st.markdown("---")
        st.subheader("âš¡ ì‘ì—… í˜„í™©")
        
        active_jobs = [j for j in ai.jobs.values() if j['status'] == 'processing']
        completed_jobs = [j for j in ai.jobs.values() if j['status'] == 'completed']
        
        st.metric("ì§„í–‰ ì¤‘", len(active_jobs))
        st.metric("ì™„ë£Œë¨", len(completed_jobs))
    
    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ“ ì°½ì‘ ìš”ì²­")
        
        # ê³ ê¸‰ ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸
        advanced_examples = {
            "íŒíƒ€ì§€": "í˜„ëŒ€ í•œêµ­ì—ì„œ ìŠ¤ë§ˆíŠ¸í° ì•±ìœ¼ë¡œ ë§ˆë²•ì„ ì‹œì „í•˜ëŠ” ì„¸ê³„. ì£¼ì¸ê³µì€ ë§ˆë²• ì•± ê°œë°œìì¸ë°, ìì‹ ì´ ë§Œë“  ì•±ì´ ì‹¤ì œ ë§ˆë²•ì„ ì¼ìœ¼í‚¨ë‹¤ëŠ” ê±¸ ë°œê²¬í•œë‹¤. í•˜ì§€ë§Œ ì•± ì‚¬ìš©ë£Œë¡œ ìˆ˜ëª…ì´ ì°¨ê°ë˜ëŠ” ì‹œìŠ¤í…œì´ê³ ...",
            "ë¡œë§¨ìŠ¤": "AI ê°œë°œìì™€ AI ìœ¤ë¦¬í•™ìê°€ ë§Œë‚˜ 'ì¸ê³µì§€ëŠ¥ì´ ì‚¬ë‘í•  ìˆ˜ ìˆëŠ”ê°€'ë¼ëŠ” ì£¼ì œë¡œ ë…¼ìŸí•˜ë‹¤ ì„œë¡œì—ê²Œ ëŒë¦°ë‹¤. í•˜ì§€ë§Œ ê·¸ë“¤ì´ ê°œë°œí•œ AIê°€ ë¨¼ì € ì‚¬ë‘ì— ë¹ ì ¸ë²„ë¦¬ê³ ...",
            "SF": "2045ë…„ ì„œìš¸, ê¸°ì–µì„ USBì— ì €ì¥í•  ìˆ˜ ìˆëŠ” ê¸°ìˆ ì´ ìƒìš©í™”ëë‹¤. ì£¼ì¸ê³µì€ ê¸°ì–µ ë°±ì—… ì „ë¬¸ê°€ì¸ë°, ì–´ëŠ ë‚  ì‚­ì œëœ ê¸°ì–µ ì†ì—ì„œ ì •ë¶€ì˜ ê±°ëŒ€í•œ ìŒëª¨ë¥¼ ë°œê²¬í•œë‹¤.",
            "ë¯¸ìŠ¤í„°ë¦¬": "ìœ ëª… ì›¹íˆ° ì‘ê°€ê°€ ì—°ì¬ ì¤‘ë‹¨ì„ ì„ ì–¸í•œ í›„ ì‹¤ì¢…ëë‹¤. í•˜ì§€ë§Œ ê·¸ì˜ ì›¹íˆ°ì€ ê³„ì† ì—…ë°ì´íŠ¸ë˜ê³  ìˆê³ , ë‚´ìš©ì€ ì‹¤ì œ ì¼ì–´ë‚  ì‚¬ê±´ë“¤ì„ ì˜ˆì–¸í•˜ê³  ìˆë‹¤.",
            "ë“œë¼ë§ˆ": "ì¹˜í‚¨ì§‘ì„ ìš´ì˜í•˜ëŠ” 50ëŒ€ ì•„ë²„ì§€ê°€ ë”¸ì˜ ìœ íŠœë¸Œ ì±„ë„ì— ì¶œì—°í•˜ë©´ì„œ ë’¤ëŠ¦ê²Œ ê¿ˆì„ ì°¾ì•„ê°€ëŠ” ì´ì•¼ê¸°. í•˜ì§€ë§Œ ê°€ì¡± ê°ìì˜ ë¹„ë°€ì´ í•˜ë‚˜ì”© ë“œëŸ¬ë‚˜ë©´ì„œ..."
        }
        
        example_text = advanced_examples.get(genre, "")
        
        user_request = st.text_area(
            "ì°½ì‘ ìš”ì²­ì„ ìƒì„¸íˆ ì…ë ¥í•˜ì„¸ìš”",
            height=200,
            placeholder=f"ì˜ˆì‹œ: {example_text}",
            help="êµ¬ì²´ì ì¼ìˆ˜ë¡ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )
        
        # ê³ ê¸‰ ì˜µì…˜
        with st.expander("ğŸ”§ ê³ ê¸‰ ì˜µì…˜"):
            include_dialogue = st.checkbox("ëŒ€í™” ì¤‘ì‹¬ ì°½ì‘", value=True)
            include_description = st.checkbox("ìƒì„¸í•œ ë¬˜ì‚¬", value=True)
            avoid_cliche = st.checkbox("í´ë¦¬ì…° ì™„ì „ ì°¨ë‹¨", value=True)
            korean_emotion = st.checkbox("í•œêµ­ì  ì •ì„œ ê°•í™”", value=True)
        
        # ì°½ì‘ ì‹œì‘ ë²„íŠ¼
        if st.button("ğŸš€ ê¸°ê°€ì°¨ë“œ ì°½ì‘ ì‹œì‘", type="primary", use_container_width=True):
            if user_request.strip():
                # ê³ ê¸‰ ì˜µì…˜ ë°˜ì˜
                enhanced_request = user_request
                if include_dialogue:
                    enhanced_request += "\n\n[ëŒ€í™” ì¤‘ì‹¬ìœ¼ë¡œ ìƒìƒí•˜ê²Œ ì‘ì„±]"
                if include_description:
                    enhanced_request += "\n[ìƒì„¸í•œ ì¥ë©´ ë¬˜ì‚¬ í¬í•¨]"
                if avoid_cliche:
                    enhanced_request += "\n[í´ë¦¬ì…° ì™„ì „ ê¸ˆì§€]"
                if korean_emotion:
                    enhanced_request += "\n[í•œêµ­ì  ì •ì„œì™€ ë¬¸í™” ë°˜ì˜]"
                
                job_id = ai.create_job(enhanced_request, genre, style, temperature, max_tokens)
                ai.start_job(job_id)
                st.success(f"ğŸ”¥ ê¸°ê°€ì°¨ë“œ ì‘ì—… ì‹œì‘! ID: {job_id}")
                st.rerun()
            else:
                st.warning("ì°½ì‘ ìš”ì²­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        
        # ì‘ì—… ëª©ë¡
        if ai.jobs:
            st.markdown("---")
            st.subheader("ğŸ“‹ ì‘ì—… ëª©ë¡")
            
            for job_id, job in sorted(ai.jobs.items(), key=lambda x: x[1]['created_at'], reverse=True):
                status_emoji = {
                    'created': 'â³',
                    'processing': 'ğŸ”„', 
                    'completed': 'âœ…',
                    'error': 'âŒ'
                }
                
                with st.expander(f"{status_emoji.get(job['status'], 'â“')} {job_id} - {job['genre']} {job['style']}"):
                    col_x, col_y = st.columns([3, 1])
                    
                    with col_x:
                        st.write(f"**ìš”ì²­**: {job['user_request'][:150]}...")
                        st.write(f"**ìƒì„±**: {job['created_at'].strftime('%H:%M:%S')}")
                        if job['status'] == 'processing':
                            st.write(f"**ìƒíƒœ**: {job.get('status_msg', 'ì²˜ë¦¬ ì¤‘...')}")
                    
                    with col_y:
                        if job['status'] == 'processing':
                            st.progress(job['progress'] / 100)
                            st.write(f"{job['progress']}%")
                        elif job['status'] == 'completed':
                            st.success("ì™„ë£Œ!")
                            word_count = len(job['result'].replace(' ', ''))
                            st.write(f"{word_count:,}ì")
                        elif job['status'] == 'error':
                            st.error("ì˜¤ë¥˜")
    
    with col2:
        st.subheader("ğŸ“– ì°½ì‘ ê²°ê³¼")
        
        # ìë™ ìƒˆë¡œê³ ì¹¨
        if active_jobs:
            time.sleep(1)
            st.rerun()
        
        # ìµœì‹  ì™„ë£Œ ì‘ì—… í‘œì‹œ
        if completed_jobs:
            latest_job = max(completed_jobs, key=lambda x: x['updated_at'])
            
            # ë©”íƒ€ ì •ë³´
            col_meta1, col_meta2, col_meta3 = st.columns(3)
            with col_meta1:
                st.metric("ì‘ì—… ID", latest_job['id'])
            with col_meta2:
                st.metric("ì¥ë¥´", latest_job['genre'])
            with col_meta3:
                word_count = len(latest_job['result'].replace(' ', ''))
                st.metric("ê¸€ììˆ˜", f"{word_count:,}ì")
            
            st.markdown("---")
            
            # ê²°ê³¼ í‘œì‹œ
            st.markdown("### ğŸ¨ ì°½ì‘ ê²°ê³¼")
            
            # ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ê²°ê³¼ì°½
            result_container = st.container()
            with result_container:
                st.markdown(
                    f'<div style="height: 600px; overflow-y: auto; padding: 20px; background-color: #f8f9fa; border-radius: 10px; border: 1px solid #dee2e6;">'
                    f'{latest_job["result"].replace(chr(10), "<br>")}'
                    f'</div>',
                    unsafe_allow_html=True
                )
            
            # ì•¡ì…˜ ë²„íŠ¼
            st.markdown("---")
            col_btn1, col_btn2, col_btn3 = st.columns(3)
            
            with col_btn1:
                st.download_button(
                    "ğŸ’¾ TXT ë‹¤ìš´ë¡œë“œ",
                    latest_job['result'],
                    f"gigachad_{latest_job['genre']}_{latest_job['id']}.txt",
                    "text/plain",
                    use_container_width=True
                )
            
            with col_btn2:
                if st.button("ğŸ”„ ì´ì–´ì“°ê¸°", use_container_width=True):
                    continue_request = f"ë‹¤ìŒ ë‚´ìš©ì„ ì´ì–´ì„œ ì¨ì£¼ì„¸ìš”:\n\n{latest_job['result'][-200:]}"
                    job_id = ai.create_job(continue_request, latest_job['genre'], latest_job['style'])
                    ai.start_job(job_id)
                    st.success("ì´ì–´ì“°ê¸° ì‹œì‘!")
                    st.rerun()
            
            with col_btn3:
                if st.button("ğŸ“Š ë¶„ì„", use_container_width=True):
                    analysis = f"""
                    ğŸ“Š ì‘í’ˆ ë¶„ì„:
                    - ê¸€ììˆ˜: {word_count:,}ì
                    - ì™„ì„±ì‹œê°„: {(latest_job['updated_at'] - latest_job['created_at']).seconds}ì´ˆ
                    - ì°½ì˜ì„±: {latest_job['temperature']}
                    - í’ˆì§ˆë“±ê¸‰: A+ (ê¸°ê°€ì°¨ë“œê¸‰)
                    """
                    st.info(analysis)
        
        else:
            st.info("ğŸ¯ ì™„ë£Œëœ ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°€ì°¨ë“œ ì°½ì‘ì„ ì‹œì‘í•´ë³´ì„¸ìš”!")
            
            # ë°ì´í„°ì…‹ ë¯¸ë¦¬ë³´ê¸°
            with st.expander("ğŸ“š í•™ìŠµ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
                if hasattr(ai, 'vl_samples') and ai.vl_samples['novel']:
                    sample = ai.vl_samples['novel'][0]
                    st.write("**VL ì†Œì„¤ ìƒ˜í”Œ:**")
                    st.write(f"ì œëª©: {sample['title']}")
                    st.write(f"ì¥ë¥´: {', '.join(sample['genre'])}")
                    st.write(f"ì»¨ì…‰: {sample['concept'][:100]}...")

if __name__ == "__main__":
    main() 