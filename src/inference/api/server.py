#!/usr/bin/env python3
"""
Loop AI ëª¨ë“ˆí™”ëœ ì¶”ë¡  ì„œë²„
ë§ì¶¤ë²• ê²€ì‚¬ ê¸°ëŠ¥ê³¼ ì±„íŒ… ê¸°ëŠ¥ì„ í†µí•©í•œ ì°½ì‘ ì§€ì› ì‹œìŠ¤í…œ
"""

import logging
import os
import sys
import time
from collections import OrderedDict
from collections.abc import AsyncGenerator
from contextlib import asynccontextmanager
from datetime import datetime, timezone
from typing import Generic, TypeVar, TypedDict, Any, TYPE_CHECKING

import uvicorn
import httpx
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import StreamingResponse
from openai import AsyncOpenAI, APIConnectionError
from pydantic import BaseModel, Field

if TYPE_CHECKING:
    from mcp.server.fastmcp import FastMCP

# MCP ê´€ë ¨ ì„í¬íŠ¸ ì¶”ê°€
mcp_available = False
try:
    # MCP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹œë„
    from mcp.server.fastmcp import FastMCP

    mcp_available = True
    logger = logging.getLogger(__name__)
    logger.info("âœ… MCP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì„±ê³µ")
except ImportError:
    FastMCP = None
    logger = logging.getLogger(__name__)
    logger.warning("âš ï¸ MCP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹¤íŒ¨: MCP ë¹„í™œì„±í™”")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
)

# ë¡œì»¬ ëª¨ë“ˆ import
from src.inference.api.handlers import ChatHandler, SpellCheckHandler
from src.inference.api.handlers.google_docs_handler import GoogleDocsHandler
from src.inference.api.handlers.location_handler import LocationHandler
from src.inference.api.handlers.web_search_handler import WebSearchHandler
from src.inference.api.handlers.assistant_handler import AssistantHandler
from src.utils.spellcheck import ModuleStats
from src.shared.prompts import loader as prompt_loader


# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# --- TypedDict ì •ì˜ ---
class ChatCompletionResult(TypedDict):
    response: str
    model: str
    cost: float
    tokens: int
    isComplete: bool | None
    continuationToken: str | None


class SpellCheckResult(TypedDict):
    success: bool
    original_text: str
    corrected_text: str
    errors_found: int
    error_words: list[str]
    accuracy: float
    total_words: int


class WebSearchResultDict(TypedDict):
    title: str
    url: str
    snippet: str
    publishedDate: str | None
    favicon: str | None


class WebSearchAPIResult(TypedDict):
    query: str
    source: str
    num_results: int
    results: list[WebSearchResultDict]
    summary: str
    timestamp: str
    from_cache: bool
    response_time: float


class WebSearchStatsResult(TypedDict):
    total_searches: int
    cache_hits: int
    cache_misses: int
    avg_response_time: float
    last_search_time: str | None
    cache_enabled: bool


# ì „ì—­ ë³€ìˆ˜
openai_client: AsyncOpenAI | None = None
chat_handler: ChatHandler | None = None
spellcheck_handler: SpellCheckHandler | None = None
location_handler: LocationHandler | None = None
web_search_handler: WebSearchHandler | None = None
google_docs_handler: GoogleDocsHandler | None = None
assistant_handler: AssistantHandler | None = None
mcp_server: Any = None


@asynccontextmanager
async def lifespan(_app: "FastAPI") -> AsyncGenerator[None, None]:
    """ì„œë²„ ì‹œì‘ ë° ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬"""
    global openai_client, chat_handler, spellcheck_handler, location_handler, web_search_handler, google_docs_handler, assistant_handler, mcp_server
    logger.info("ğŸš€ ì„œë²„ ì‹œì‘ ì´ë²¤íŠ¸ ë°œìƒ")

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì™¸ë¶€ API ì—°ë™ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")

    # ë” ê²¬ê³ í•œ HTTP í´ë¼ì´ì–¸íŠ¸ë¥¼ ìœ„í•œ íƒ€ì„ì•„ì›ƒ ì„¤ì •
    timeout = httpx.Timeout(10.0, connect=5.0)
    openai_client = AsyncOpenAI(api_key=api_key, timeout=timeout)
    logger.info("âœ… (Async) OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (íƒ€ì„ì•„ì›ƒ ì„¤ì • ì ìš©)")

    # í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
    chat_handler = ChatHandler(openai_client)
    spellcheck_handler = SpellCheckHandler(openai_client)
    location_handler = LocationHandler()
    web_search_handler = WebSearchHandler(openai_client)
    assistant_handler = AssistantHandler(openai_client, web_search_handler)
    
    try:
        google_docs_handler = GoogleDocsHandler()
        logger.info("âœ… Google Docs í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” ì„±ê³µ")
    except Exception as e:
        google_docs_handler = None
        logger.warning(f"âš ï¸ Google Docs í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” ì‹¤íŒ¨. ê´€ë ¨ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤. ì˜¤ë¥˜: {e}")

    chat_handler.load_datasets()
    logger.info("âœ… ëª¨ë“  í•¸ë“¤ëŸ¬ ë° ë°ì´í„°ì…‹ ì´ˆê¸°í™” ì™„ë£Œ")

    # MCP ì„œë²„ ì„¤ì •
    if mcp_available and FastMCP is not None:
        try:
            mcp_server = FastMCP("loop_ai", stateless_http=True)
            logger.info("âœ… MCP ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ MCP ì„œë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            mcp_server = None
    yield
    logger.info("ğŸŒ™ ì„œë²„ ì¢…ë£Œ.")


# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Loop AI API",
    description="Loop AI ì°½ì‘ ì§€ì› ì‹œìŠ¤í…œ - ì±„íŒ…, ë§ì¶¤ë²• ê²€ì‚¬, ì‹œë†‰ì‹œìŠ¤ ìƒì„±",
    version="3.0.0",
    lifespan=lifespan,
)


# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Gzip ì••ì¶• ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€: ëª¨ë“  ì‘ë‹µì„ ì••ì¶•í•˜ì—¬ ë„¤íŠ¸ì›Œí¬ ì „ì†¡ëŸ‰ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.
# minimum_size=1000: 1000ë°”ì´íŠ¸ ì´ìƒì˜ ì‘ë‹µë§Œ ì••ì¶•í•©ë‹ˆë‹¤.
app.add_middleware(GZipMiddleware, minimum_size=1000)


# ë¹„ìš© ì¶”ì 
PRICING_PER_TOKEN = {
    "gpt-4o-mini": {"input": 0.00015 / 1000, "output": 0.0006 / 1000},
    "gpt-4o": {"input": 0.005 / 1000, "output": 0.015 / 1000},
    "gpt-3.5-turbo": {"input": 0.0005 / 1000, "output": 0.0015 / 1000},
}

monthly_usage = {"cost": 0.0, "tokens": 0}
MONTHLY_BUDGET = float(os.getenv("OPENAI_MONTHLY_BUDGET", "15.0"))

# LRU ìºì‹œ ì œë„¤ë¦­ íƒ€ì… ì •ì˜
K = TypeVar("K")
V = TypeVar("V")


# LRU ìºì‹œ êµ¬í˜„
class LRUCache(Generic[K, V]):
    def __init__(self, capacity: int = 1024):
        self.cache: OrderedDict[K, V] = OrderedDict()
        self.capacity: int = capacity

    def get(self, key: K) -> V | None:
        if key not in self.cache:
            return None
        self.cache.move_to_end(key)
        return self.cache[key]

    def put(self, key: K, value: V) -> None:
        if key in self.cache:
            self.cache.move_to_end(key)
        elif len(self.cache) >= self.capacity:
            _ = self.cache.popitem(last=False)
        self.cache[key] = value


response_cache: LRUCache[str, str] = LRUCache()


# API ëª¨ë¸ ì •ì˜
class ChatMessage(BaseModel):
    role: str = Field(..., description="ë©”ì‹œì§€ ì—­í•  (user/assistant)")
    content: str = Field(..., description="ë©”ì‹œì§€ ë‚´ìš©")


class ChatRequest(BaseModel):
    message: str = Field(..., description="ì‚¬ìš©ì ë©”ì‹œì§€")
    history: list[ChatMessage] = Field(default=[], description="ì±„íŒ… íˆìŠ¤í† ë¦¬")
    model: str | None = Field(None, description="ì‚¬ìš©í•  ëª¨ë¸")
    maxTokens: int = Field(4000, description="ìµœëŒ€ í† í° ìˆ˜")
    isLongForm: bool = Field(False, description="ê¸´ í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë“œ")
    continueStory: bool = Field(False, description="ì´ì•¼ê¸° ê³„ì†í•˜ê¸° ëª¨ë“œ")


class ChatResponse(BaseModel):
    response: str = Field(..., description="AI ì‘ë‹µ")
    model: str = Field(..., description="ì‚¬ìš©ëœ ëª¨ë¸")
    cost: float = Field(..., description="ë¹„ìš© (USD)")
    tokens: int = Field(..., description="ì‚¬ìš©ëœ í† í° ìˆ˜")
    isComplete: bool | None = Field(True, description="ì‘ë‹µ ì™„ë£Œ ì—¬ë¶€")


class SpellCheckRequest(BaseModel):
    text: str = Field(..., description="ë§ì¶¤ë²• ê²€ì‚¬í•  í…ìŠ¤íŠ¸")
    auto_correct: bool = Field(default=True, description="ìë™ ìˆ˜ì • ì—¬ë¶€")
    # AI ê¸°ë°˜ êµì •ì„ ìœ„í•œ í•„ë“œ ì¶”ê°€
    full_document: str | None = Field(None, description="ì „ì²´ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸")
    use_ai: bool = Field(default=False, description="AI ê¸°ë°˜ ë¬¸ë§¥ êµì • ì‚¬ìš© ì—¬ë¶€")


class SpellCheckResponse(BaseModel):
    original_text: str = Field(..., description="ì›ë³¸ í…ìŠ¤íŠ¸")
    corrected_text: str = Field(..., description="ìˆ˜ì •ëœ í…ìŠ¤íŠ¸")
    errors_found: int = Field(..., description="ë°œê²¬ëœ ì˜¤íƒ€ ìˆ˜")
    error_words: list[str] = Field(..., description="ì˜¤íƒ€ ë‹¨ì–´ ëª©ë¡")
    accuracy: float = Field(..., description="ì •í™•ë„ (%)")
    total_words: int = Field(..., description="ì´ ë‹¨ì–´ ìˆ˜")
    # AI ê¸°ë°˜ êµì • ê²°ê³¼ë¥¼ ìœ„í•œ í•„ë“œ ì¶”ê°€
    reason: str | None = Field(None, description="AI êµì • ì´ìœ ")
    context_analysis: str | None = Field(None, description="AI ë¬¸ë§¥ ë¶„ì„ ê²°ê³¼")


class SentenceImprovementRequest(BaseModel):
    original_sentence: str = Field(..., description="ê°œì„ ì„ ì›í•˜ëŠ” ì›ë³¸ ë¬¸ì¥")
    genre: str = Field(..., description="ì‘í’ˆì˜ ì¥ë¥´")
    character_profile: str = Field(..., description="ë¬¸ì¥ì„ ë§í•˜ëŠ” ìºë¦­í„°ì˜ í”„ë¡œí•„")
    context: str = Field(..., description="ë¬¸ì¥ì˜ ì•ë’¤ ë¬¸ë§¥")
    model: str | None = Field(None, description="ì‚¬ìš©í•  ëª¨ë¸ (e.g., gpt-4o-mini)")


class SentenceImprovementResponse(BaseModel):
    suggestions: dict[str, Any]
    model: str
    cost: float
    tokens: int


class CostStatusResponse(BaseModel):
    monthly_cost: float
    monthly_budget: float
    usage_percentage: float
    total_tokens: int
    cache_hits: int


class LocationSuggestRequest(BaseModel):
    query: str = Field(..., description="ì¶”ì²œì„ ìœ„í•œ ê²€ìƒ‰ì–´ (ë„ì‹œ/ì§€ì—­ëª…)")


class LocationSuggestResponse(BaseModel):
    suggestions: list[str] = Field(..., description="ì¶”ì²œëœ ì§€ì—­Â·ë„ì‹œëª… ëª©ë¡")


class WebSearchRequest(BaseModel):
    query: str = Field(..., description="ê²€ìƒ‰ì–´")
    source: str = Field(
        default="web", description="ê²€ìƒ‰ ì†ŒìŠ¤ (web, research, wiki, github, company)"
    )
    num_results: int = Field(default=5, ge=1, le=10, description="ê²°ê³¼ ê°œìˆ˜ (1-10)")
    include_summary: bool = Field(default=True, description="AI ìš”ì•½ í¬í•¨ ì—¬ë¶€")


class WebSearchResult(BaseModel):
    title: str
    url: str
    snippet: str
    publishedDate: str | None = None
    favicon: str | None = None


class WebSearchResponse(BaseModel):
    query: str
    source: str
    num_results: int
    results: list[WebSearchResult]
    summary: str = ""
    timestamp: str
    from_cache: bool = False
    response_time: float


class WebSearchStatsResponse(BaseModel):
    total_searches: int
    cache_hits: int
    cache_misses: int
    avg_response_time: float
    last_search_time: str | None
    cache_enabled: bool


class PlotHoleDetectionRequest(BaseModel):
    full_story_text: str = Field(..., min_length=100, description="ë¶„ì„í•  ì „ì²´ ìŠ¤í† ë¦¬ í…ìŠ¤íŠ¸")
    model: str | None = Field("gpt-4o", description="ì‚¬ìš©í•  AI ëª¨ë¸")


class PlotHoleDetectionResponse(BaseModel):
    detection_report: str = Field(..., description="í”Œë¡¯ í™€ íƒì§€ ê²°ê³¼ ë³´ê³ ì„œ")
    model: str
    cost: float
    tokens: int


class SmartSentenceImprovementRequest(BaseModel):
    original_text: str = Field(..., description="ê°œì„ ì„ ì›í•˜ëŠ” ì›ë³¸ í…ìŠ¤íŠ¸")
    model: str | None = Field(None, description="ì‚¬ìš©í•  AI ëª¨ë¸ (e.g., gpt-4o-mini)")


class SmartSentenceImprovementResponse(BaseModel):
    improvement_suggestions: str
    model: str
    cost: float
    tokens: int


class CharacterConsistencyRequest(BaseModel):
    character_name: str = Field(..., description="ë¶„ì„í•  ìºë¦­í„° ì´ë¦„")
    personality: str = Field(..., description="ìºë¦­í„° ì„±ê²©")
    speech_style: str = Field(..., description="ìºë¦­í„° ë§íˆ¬")
    core_values: str = Field(..., description="ìºë¦­í„° í•µì‹¬ ê°€ì¹˜ê´€/ëª©í‘œ")
    other_settings: str = Field("", description="ê¸°íƒ€ ì„¤ì •")
    story_text_for_analysis: str = Field(..., description="ë¶„ì„í•  ì‘í’ˆ í…ìŠ¤íŠ¸")
    model: str | None = Field("gpt-4o", description="ì‚¬ìš©í•  AI ëª¨ë¸")


class CharacterConsistencyResponse(BaseModel):
    consistency_report: str = Field(..., description="ìºë¦­í„° ì¼ê´€ì„± ê²€ì¦ ë³´ê³ ì„œ")
    model: str
    cost: float
    tokens: int


class CliffhangerRequest(BaseModel):
    genre: str = Field(..., description="ì‘í’ˆì˜ ì¥ë¥´")
    scene_context: str = Field(..., description="í´ë¦¬í”„í–‰ì–´ë¥¼ ìƒì„±í•  ì¥ë©´ì˜ ë§¥ë½")
    model: str | None = Field("gpt-4o", description="ì‚¬ìš©í•  AI ëª¨ë¸")


class CliffhangerSuggestion(BaseModel):
    suggestion: str
    expected_reaction: str


class CliffhangerResponse(BaseModel):
    suggestions: list[CliffhangerSuggestion]
    model: str
    cost: float
    tokens: int


class ReaderResponseRequest(BaseModel):
    platform: str = Field(..., description="íƒ€ê²Ÿ ì›¹ì†Œì„¤ í”Œë«í¼ (e.g., 'ì¹´ì¹´ì˜¤í˜ì´ì§€', 'ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ')")
    scene_context: str = Field(..., description="ë¶„ì„í•  ì¥ë©´ì˜ ë§¥ë½")
    model: str | None = Field("gpt-4o", description="ì‚¬ìš©í•  AI ëª¨ë¸")


class ReaderResponseResponse(BaseModel):
    prediction_report: dict[str, Any]
    model: str
    cost: float
    tokens: int


def calculate_cost(prompt_tokens: int, completion_tokens: int, model: str) -> float:
    """í† í° ì‚¬ìš©ëŸ‰ì— ë”°ë¥¸ ë¹„ìš© ê³„ì‚°"""
    model_pricing = PRICING_PER_TOKEN.get(model, {"input": 0, "output": 0})
    cost = (
        prompt_tokens * model_pricing["input"]
        + completion_tokens * model_pricing["output"]
    )
    monthly_usage["cost"] += cost
    monthly_usage["tokens"] += prompt_tokens + completion_tokens
    return cost


@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {"message": "Loop AI ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤."}


@app.post("/api/chat")
async def chat_endpoint(request: ChatRequest) -> StreamingResponse:
    """
    ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    if not chat_handler or not openai_client:
        raise HTTPException(
            status_code=503,
            detail="ì„œë²„ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        )

    try:
        # 1. ì‚¬ìš©ì ì˜ë„ ë° ë ˆë²¨ íŒŒì•…
        intent, level = chat_handler.detect_intent_and_level(request.message)

        # 2. ì˜ë„ì— ë”°ë¥¸ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„± ë˜ëŠ” í•¸ë“¤ëŸ¬ í˜¸ì¶œ
        if intent == "web_search":
            generator = chat_handler.handle_web_search(request.message)
        else:
            # 'greeting' ì˜ë„ì¼ ê²½ìš° 'general' í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ë§¤í•‘
            prompt_name = "general" if intent == "greeting" else intent
            
            # 2a. í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = prompt_loader.get_prompt(
                prompt_name, user_message=request.message, level=level
            )
            # 2b. í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
            generator = chat_handler.generate_response(
                prompt=prompt,
                max_tokens=request.maxTokens,
                temperature=0.7,
            )
        
        # 3. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°˜í™˜
        return StreamingResponse(generator, media_type="text/event-stream")

    except ValueError as e:
        logger.error(f"í”„ë¡¬í”„íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except APIConnectionError as e:
        logger.error(f"OpenAI API ì—°ê²° ì˜¤ë¥˜: {e.__cause__}")
        raise HTTPException(
            status_code=503, detail="ì™¸ë¶€ API ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    except Exception as e:
        logger.exception(f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


@app.post("/api/spellcheck", response_model=SpellCheckResponse)
async def spellcheck_endpoint(request: SpellCheckRequest) -> SpellCheckResponse:
    """ë§ì¶¤ë²• ê²€ì‚¬ ì—”ë“œí¬ì¸íŠ¸"""
    if not spellcheck_handler:
        raise HTTPException(
            status_code=503,
            detail="ì„œë²„ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        )

    try:
        if request.use_ai and request.full_document:
            # AI ê¸°ë°˜ ë¬¸ë§¥ êµì •
            result = await spellcheck_handler.context_aware_correction(
                target_text=request.text, full_document=request.full_document
            )
        else:
            # ê¸°ì¡´ ë¡œì»¬ êµì •
            result = spellcheck_handler.create_spellcheck_response(
            request.text, request.auto_correct
        )
        
        # TypedDictì—ì„œ Pydantic ëª¨ë¸ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
        return SpellCheckResponse(
            original_text=result.get("original_text", request.text),
            corrected_text=result.get("corrected_text", request.text),
            errors_found=result.get("errors_found", 0),
            error_words=result.get("error_words", []),
            accuracy=result.get("accuracy", 100.0),
            total_words=result.get("total_words", 0),
            reason=result.get("reason"),
            context_analysis=result.get("context_analysis"),
        )

    except Exception as e:
        logger.exception(f"ë§ì¶¤ë²• ê²€ì‚¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/cost-status", response_model=CostStatusResponse)
async def get_cost_status():
    """ì›”ë³„ ë¹„ìš© ì‚¬ìš© í˜„í™© ì¡°íšŒ"""
    cost = monthly_usage["cost"]
    tokens = monthly_usage["tokens"]
    usage_percentage = (cost / MONTHLY_BUDGET) * 100 if MONTHLY_BUDGET > 0 else 0

    return CostStatusResponse(
        monthly_cost=round(cost, 4),
        monthly_budget=MONTHLY_BUDGET,
        usage_percentage=round(usage_percentage, 2),
        total_tokens=int(tokens),
        cache_hits=response_cache.capacity - len(response_cache.cache),
    )


@app.get("/api/spellcheck/stats")
async def get_spellcheck_stats() -> ModuleStats:
    """ë§ì¶¤ë²• ê²€ì‚¬ê¸° í†µê³„ ì¡°íšŒ"""
    if not spellcheck_handler:
        raise HTTPException(status_code=503, detail="ë§ì¶¤ë²• ê²€ì‚¬ê¸° ì¤€ë¹„ ì•ˆë¨")
    return spellcheck_handler.get_statistics()


@app.get("/api/health")
async def health_check():
    """
    ì„œë²„ì˜ ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤.
    - OpenAI API ì—°ê²° ìƒíƒœ í™•ì¸
    - í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” ì—¬ë¶€ í™•ì¸
    """
    status = {"status": "ok", "timestamp": datetime.now(timezone.utc).isoformat()}
    details = {}

    # OpenAI ì—°ê²° ìƒíƒœ í™•ì¸
    if openai_client:
        try:
            _ = await openai_client.models.list(timeout=5)
            details["openai_api"] = "connected"
        except Exception as e:
            details["openai_api"] = f"disconnected: {e}"
            status["status"] = "error"
    else:
        details["openai_api"] = "not_initialized"
        status["status"] = "error"

    # í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” í™•ì¸
    details["chat_handler"] = "initialized" if chat_handler else "not_initialized"
    if not chat_handler:
        status["status"] = "error"
        
    if status["status"] == "ok":
        return status
    else:
        raise HTTPException(status_code=503, detail=details)

@app.post("/api/location-suggest", response_model=LocationSuggestResponse)
async def suggest_locations(request: LocationSuggestRequest) -> LocationSuggestResponse:
    """ì§€ì—­/ë„ì‹œëª… ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸"""
    if not location_handler:
        raise HTTPException(status_code=503, detail="Location handler not ready")

    suggestions = location_handler.suggest_locations(request.query)
    return LocationSuggestResponse(suggestions=suggestions)


@app.post("/api/web-search", response_model=WebSearchResponse)
async def web_search(request: WebSearchRequest) -> WebSearchResponse:
    """ì›¹ ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸"""
    if not web_search_handler:
        raise HTTPException(status_code=503, detail="Web search handler not ready")

    start_time = time.time()
    # search ë©”ì„œë“œëŠ” (summary, results_list) íŠœí”Œì„ ë°˜í™˜
    summary, search_results = await web_search_handler.search(
            query=request.query,
            source=request.source,
            num_results=request.num_results,
            include_summary=request.include_summary,
        )
    end_time = time.time()

    # WebSearchResult ëª¨ë¸ë¡œ ë³€í™˜
    validated_results = [WebSearchResult(**r) for r in search_results]

    return WebSearchResponse(
        query=request.query, # ìš”ì²­ì—ì„œ queryë¥¼ ê°€ì ¸ì˜´
        source=request.source, # ìš”ì²­ì—ì„œ sourceë¥¼ ê°€ì ¸ì˜´
        num_results=len(validated_results),
        results=validated_results,
        summary=summary,
        timestamp=datetime.fromtimestamp(start_time).isoformat(),
        from_cache=False, # TODO: ìºì‹œ ë¡œì§ê³¼ ì—°ë™ í•„ìš”
        response_time=(end_time - start_time),
    )


@app.get("/api/web-search/stats", response_model=WebSearchStatsResponse)
async def get_web_search_stats() -> WebSearchStatsResponse:
    """ì›¹ ê²€ìƒ‰ í†µê³„ ì¡°íšŒ"""
    if not web_search_handler:
        raise HTTPException(status_code=503, detail="Web search handler not ready")
    stats = web_search_handler.get_statistics()
    # TypedDictë¥¼ Pydantic ëª¨ë¸ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
    return WebSearchStatsResponse(
        total_searches=stats.get("total_searches", 0),
        cache_hits=stats.get("cache_hits", 0),
        cache_misses=stats.get("cache_misses", 0),
        avg_response_time=stats.get("avg_response_time", 0.0),
        last_search_time=stats.get("last_search_time"),
        cache_enabled=stats.get("cache_enabled", False),
    )


@app.delete("/api/web-search/cache")
async def clear_web_search_cache():
    """ì›¹ ê²€ìƒ‰ ìºì‹œ ì‚­ì œ"""
    if not web_search_handler:
        raise HTTPException(status_code=503, detail="Web search handler not ready")
    await web_search_handler.clear_cache()
    return {"status": "Web search cache cleared"}


@app.post("/api/improve-sentence", response_model=SentenceImprovementResponse)
async def improve_sentence_endpoint(request: SentenceImprovementRequest):
    """
    AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ì„ 3ê°€ì§€ ë²„ì „ìœ¼ë¡œ ê°œì„ í•©ë‹ˆë‹¤.
    - ìƒìƒí•œ ë¬˜ì‚¬ ë²„ì „
    - ê°„ê²°í•˜ê³  í˜ìˆëŠ” ë²„ì „
    - ìºë¦­í„°ì˜ ëª©ì†Œë¦¬ ë²„ì „
    """
    if not assistant_handler:
        raise HTTPException(status_code=503, detail="Assistant handler is not initialized")
    
    try:
        result = await assistant_handler.improve_sentence(
            original_sentence=request.original_sentence,
            genre=request.genre,
            character_profile=request.character_profile,
            context=request.context,
            model=request.model,
        )
        return SentenceImprovementResponse(
            suggestions=result["suggestions"],
            model=result["model"],
            cost=result["cost"],
            tokens=result["tokens"],
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"ë¬¸ì¥ ê°œì„  ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
        raise HTTPException(status_code=500, detail="Internal Server Error")


@app.post("/api/clear_cache")
async def clear_cache_endpoint():
    """ëª¨ë“  ìºì‹œë¥¼ ì§€ì›ë‹ˆë‹¤."""
    if chat_handler:
        _ = chat_handler.clear_cache()
    if web_search_handler:
        _ = await web_search_handler.clear_cache()
    response_cache.cache.clear()
    logger.info("ëª¨ë“  ì„œë²„ ìºì‹œê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
    return {"message": "All server caches cleared successfully."}


@app.post(
    "/api/v1/story/analyze/plot-holes",
    response_model=PlotHoleDetectionResponse,
    tags=["AI Assistant"],
    summary="ì‹¤ì‹œê°„ í”Œë¡¯ í™€ ê°ì§€",
    description="ì´ì•¼ê¸° ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í”Œë¡¯ í™€, ì„¤ì • ì¶©ëŒ ë“±ì„ ê°ì§€í•©ë‹ˆë‹¤.",
)
async def detect_plot_holes_endpoint(request: PlotHoleDetectionRequest) -> PlotHoleDetectionResponse:
    if not assistant_handler:
        raise HTTPException(
            status_code=503, detail="AssistantHandler is not initialized"
        )
    try:
        result = await assistant_handler.detect_plot_holes(
            full_story_text=request.full_story_text, model=request.model
        )
        return PlotHoleDetectionResponse(**result)
    except ValueError as e:
        logger.error(f"í”Œë¡¯ í™€ ê°ì§€ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.exception("í”Œë¡¯ í™€ ê°ì§€ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ")
        raise HTTPException(status_code=500, detail="Internal Server Error")


@app.post(
    "/api/v1/story/analyze/character-consistency",
    response_model=CharacterConsistencyResponse,
    tags=["AI Assistant"],
    summary="ìºë¦­í„° ì¼ê´€ì„± ì²´í¬",
    description="ìºë¦­í„° í”„ë¡œí•„ê³¼ ì‹¤ì œ ì‘í’ˆ ë‚´ìš©ì„ ë¹„êµí•˜ì—¬ ì„¤ì • ë¶•ê´´ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.",
)
async def check_character_consistency_endpoint(
    request: CharacterConsistencyRequest,
) -> CharacterConsistencyResponse:
    if not assistant_handler:
        raise HTTPException(
            status_code=503, detail="AssistantHandler is not initialized"
        )
    try:
        result = await assistant_handler.check_character_consistency(
            character_name=request.character_name,
            personality=request.personality,
            speech_style=request.speech_style,
            core_values=request.core_values,
            other_settings=request.other_settings,
            story_text_for_analysis=request.story_text_for_analysis,
            model=request.model,
        )
        return CharacterConsistencyResponse(**result)
    except ValueError as e:
        logger.error(f"ìºë¦­í„° ì¼ê´€ì„± ê²€ì¦ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.exception("ìºë¦­í„° ì¼ê´€ì„± ê²€ì¦ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ")
        raise HTTPException(status_code=500, detail="Internal Server Error")


@app.post(
    "/api/v1/story/generate/cliffhanger",
    response_model=CliffhangerResponse,
    tags=["AI Assistant"],
    summary="ì§€ëŠ¥í˜• í´ë¦¬í”„í–‰ì–´ ìƒì„±ê¸°",
    description="ì¥ë¥´ì™€ ì¥ë©´ ë§¥ë½ì— ë§ëŠ” í´ë¦¬í”„í–‰ì–´ ì•„ì´ë””ì–´ë¥¼ ë…ì ë°˜ì‘ ì˜ˆì¸¡ê³¼ í•¨ê»˜ ì œì•ˆí•©ë‹ˆë‹¤.",
)
async def generate_cliffhanger_endpoint(request: CliffhangerRequest) -> CliffhangerResponse:
    if not assistant_handler:
        raise HTTPException(
            status_code=503, detail="AssistantHandler is not initialized"
        )
    try:
        result = await assistant_handler.generate_cliffhanger(
            genre=request.genre, scene_context=request.scene_context, model=request.model
        )
        suggestions_list = [CliffhangerSuggestion(**item) for item in result.get("suggestions", [])]
        return CliffhangerResponse(
            suggestions=suggestions_list,
            model=result.get("model", "unknown"),
            cost=result.get("cost", 0.0),
            tokens=result.get("tokens", 0),
        )
    except ValueError as e:
        logger.error(f"í´ë¦¬í”„í–‰ì–´ ìƒì„± API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.exception("í´ë¦¬í”„í–‰ì–´ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ")
        raise HTTPException(status_code=500, detail="Internal Server Error")


@app.post(
    "/api/v1/story/predict/reader-response",
    response_model=ReaderResponseResponse,
    tags=["AI Assistant"],
    summary="ë…ì ë°˜ì‘ ì˜ˆì¸¡ AI",
    description="íŠ¹ì • ì¥ë©´ì— ëŒ€í•œ í”Œë«í¼ë³„ ë…ì ë°˜ì‘(ëŒ“ê¸€, ì´íƒˆë¥  ë“±)ì„ ì˜ˆì¸¡í•˜ê³  ê°œì„ ì•ˆì„ ì œì•ˆí•©ë‹ˆë‹¤.",
)
async def predict_reader_response_endpoint(request: ReaderResponseRequest) -> ReaderResponseResponse:
    if not assistant_handler:
        raise HTTPException(
            status_code=503, detail="AssistantHandler is not initialized"
        )
    try:
        result = await assistant_handler.predict_reader_response(
            platform=request.platform,
            scene_context=request.scene_context,
            model=request.model,
        )
        return ReaderResponseResponse(
            prediction_report=result.get("prediction_report", {}),
            model=result.get("model", "unknown"),
            cost=result.get("cost", 0.0),
            tokens=result.get("tokens", 0),
        )
    except ValueError as e:
        logger.error(f"ë…ì ë°˜ì‘ ì˜ˆì¸¡ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.exception("ë…ì ë°˜ì‘ ì˜ˆì¸¡ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ")
        raise HTTPException(status_code=500, detail="Internal Server Error")


@app.post(
    "/api/v1/story/analyze/sentence-improvement",
    response_model=SmartSentenceImprovementResponse,
    tags=["AI Assistant"],
    summary="ìŠ¤ë§ˆíŠ¸ ë¬¸ì¥ ê°œì„ ",
    description="ë‹¨ì¼ ë¬¸ì¥ ë˜ëŠ” ì§§ì€ ë‹¨ë½ì„ ë¶„ì„í•˜ì—¬ ë¬¸ì²´, ë¦¬ë“¬, ëª…í™•ì„± ì¸¡ë©´ì—ì„œ ì—¬ëŸ¬ ê°œì„ ì•ˆì„ ì œì•ˆí•©ë‹ˆë‹¤.",
)
async def smart_sentence_improvement_endpoint(
    request: SmartSentenceImprovementRequest,
) -> SmartSentenceImprovementResponse:
    if not assistant_handler:
        raise HTTPException(
            status_code=503, detail="AssistantHandler is not initialized"
        )
    try:
        result = await assistant_handler.run_smart_sentence_improvement(
            original_text=request.original_text, model=request.model
        )
        return SmartSentenceImprovementResponse(**result)
    except ValueError as e:
        logger.error(f"ìŠ¤ë§ˆíŠ¸ ë¬¸ì¥ ê°œì„  API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.exception("ìŠ¤ë§ˆíŠ¸ ë¬¸ì¥ ê°œì„  ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ")
        raise HTTPException(status_code=500, detail="Internal Server Error")


# --- ì—í”¼ì†Œë“œ ê¸¸ì´ ìµœì í™” ---
class EpisodeLengthRequest(BaseModel):
    platform: str = Field(..., description="íƒ€ê²Ÿ ì›¹ì†Œì„¤ í”Œë«í¼ (e.g., 'ì¹´ì¹´ì˜¤í˜ì´ì§€', 'ë„¤ì´ë²„ ì‹œë¦¬ì¦ˆ')")
    episode_text: str = Field(..., description="ë¶„ëŸ‰ì´ ìµœì í™”ë  ì „ì²´ ì—í”¼ì†Œë“œ í…ìŠ¤íŠ¸")
    model: str | None = Field("gpt-4o", description="ì‚¬ìš©í•  AI ëª¨ë¸")

class EpisodeLengthResponse(BaseModel):
    optimization_report: dict[str, Any]
    model: str
    cost: float
    tokens: int

@app.post(
    "/api/v1/story/optimize/episode-length",
    response_model=EpisodeLengthResponse,
    tags=["AI Assistant"],
    summary="ì—í”¼ì†Œë“œ ê¸¸ì´ ìµœì í™”",
    description="í”Œë«í¼ íŠ¹ì„±ì— ë§ì¶° ì—í”¼ì†Œë“œ ë¶„ëŸ‰ ë° ë¶„í•  ì§€ì ì„ ìµœì í™”í•©ë‹ˆë‹¤.",
)
async def optimize_episode_length_endpoint(request: EpisodeLengthRequest) -> EpisodeLengthResponse:
    """ì—í”¼ì†Œë“œ ê¸¸ì´ ìµœì í™” AI ì—”ë“œí¬ì¸íŠ¸"""
    if not assistant_handler:
        raise HTTPException(
            status_code=503, detail="AssistantHandler is not initialized"
        )
    try:
        result = await assistant_handler.optimize_episode_length(
            platform=request.platform,
            episode_text=request.episode_text,
            model=request.model,
        )
        return EpisodeLengthResponse(
            optimization_report=result.get("optimization_report", {}),
            model=result.get("model", "unknown"),
            cost=result.get("cost", 0.0),
            tokens=result.get("tokens", 0),
        )
    except ValueError as e:
        logger.error(f"ì—í”¼ì†Œë“œ ê¸¸ì´ ìµœì í™” API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.exception("ì—í”¼ì†Œë“œ ê¸¸ì´ ìµœì í™” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ")
        raise HTTPException(status_code=500, detail="Internal Server Error")


# --- AI ë² íƒ€ë¦¬ë” ---
class BetaReadRequest(BaseModel):
    manuscript: str = Field(..., description="ë² íƒ€ ë¦¬ë”©ì„ ìš”ì²­í•  ì›ê³  ì „ë¬¸")
    genre: str = Field(..., description="ì‘í’ˆì˜ ì¥ë¥´")
    target_audience: str = Field(..., description="íƒ€ê²Ÿ ë…ìì¸µ")
    author_concerns: str | None = Field(None, description="ì‘ê°€ê°€ íŠ¹ë³„íˆ ìš°ë ¤í•˜ëŠ” ì ")
    model: str | None = Field("gpt-4o", description="ì‚¬ìš©í•  AI ëª¨ë¸")

class BetaReadResponse(BaseModel):
    beta_read_report: dict[str, Any]
    model: str
    cost: float
    tokens: int

@app.post(
    "/api/v1/story/analyze/beta-read",
    response_model=BetaReadResponse,
    tags=["AI Assistant"],
    summary="AI ë² íƒ€ë¦¬ë” ì¢…í•© ë¶„ì„",
    description="ì›ê³  ì „ì²´ë¥¼ ë‹¤ê°ë„ë¡œ ë¶„ì„í•˜ì—¬ ì¢…í•©ì ì¸ í”¼ë“œë°± ë¦¬í¬íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
)
async def request_beta_read_endpoint(request: BetaReadRequest) -> BetaReadResponse:
    """AI ë² íƒ€ë¦¬ë” ì—”ë“œí¬ì¸íŠ¸"""
    if not assistant_handler:
        raise HTTPException(
            status_code=503, detail="AssistantHandler is not initialized"
        )
    try:
        result = await assistant_handler.get_beta_read_feedback(
            manuscript=request.manuscript,
            genre=request.genre,
            target_audience=request.target_audience,
            author_concerns=request.author_concerns,
            model=request.model,
        )
        return BetaReadResponse(
            beta_read_report=result.get("beta_read_report", {}),
            model=result.get("model", "unknown"),
            cost=result.get("cost", 0.0),
            tokens=result.get("tokens", 0),
        )
    except ValueError as e:
        logger.error(f"AI ë² íƒ€ë¦¬ë”© API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.exception("AI ë² íƒ€ë¦¬ë”© ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ")
        raise HTTPException(status_code=500, detail="Internal Server Error")


# --- íŠ¸ë Œë“œ ë¶„ì„ & ì ìš© ---
class TrendAnalysisRequest(BaseModel):
    genre: str = Field(..., description="ë¶„ì„í•  ì‘í’ˆì˜ ì¥ë¥´")
    synopsis: str = Field(..., description="ì‘í’ˆì˜ ê°„ë‹¨í•œ ì‹œë†‰ì‹œìŠ¤")
    keywords: list[str] = Field(default=[], description="ì‘í’ˆì˜ í•µì‹¬ í‚¤ì›Œë“œ")
    platform: str = Field("ì¹´ì¹´ì˜¤í˜ì´ì§€", description="ë¶„ì„ì„ ì›í•˜ëŠ” íƒ€ê²Ÿ í”Œë«í¼")
    model: str | None = Field("gpt-4o", description="ì‚¬ìš©í•  AI ëª¨ë¸")

class TrendAnalysisResponse(BaseModel):
    trend_report: str
    model: str
    cost: float
    tokens: int
    searched_data: list[dict[str, Any]]

@app.post(
    "/api/v1/story/analyze/trends",
    response_model=TrendAnalysisResponse,
    tags=["AI Assistant"],
    summary="ì›¹ì†Œì„¤ íŠ¸ë Œë“œ ë¶„ì„ ë° ì ìš©",
    description="ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ìµœì‹  íŠ¸ë Œë“œë¥¼ ë¶„ì„í•˜ê³ , ì‘í’ˆì— ì ìš©í•  ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.",
)
async def analyze_trends_endpoint(request: TrendAnalysisRequest) -> TrendAnalysisResponse:
    if not assistant_handler or not assistant_handler.web_search_handler:
        raise HTTPException(
            status_code=503, detail="AssistantHandler or WebSearchHandler is not initialized"
        )
    try:
        result = await assistant_handler.analyze_trends(
            genre=request.genre,
            synopsis=request.synopsis,
            keywords=request.keywords,
            platform=request.platform,
            model=request.model,
        )
        return TrendAnalysisResponse(**result)
    except ValueError as e:
        logger.error(f"íŠ¸ë Œë“œ ë¶„ì„ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.exception("íŠ¸ë Œë“œ ë¶„ì„ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ")
        raise HTTPException(status_code=500, detail="Internal Server Error")


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
