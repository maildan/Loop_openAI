#!/usr/bin/env python3
"""
Loop AI ëª¨ë“ˆí™”ëœ ì¶”ë¡  ì„œë²„
ë§ì¶¤ë²• ê²€ì‚¬ ê¸°ëŠ¥ê³¼ ì±„íŒ… ê¸°ëŠ¥ì„ í†µí•©í•œ ì°½ì‘ ì§€ì› ì‹œìŠ¤í…œ
"""

import logging
import os
import sys
import time
from collections import OrderedDict
from collections.abc import AsyncGenerator
from contextlib import asynccontextmanager
from datetime import datetime, timezone
from typing import Generic, TypeVar, TypedDict, Any, TYPE_CHECKING

import uvicorn
import httpx
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import StreamingResponse
from openai import AsyncOpenAI, APIConnectionError
from pydantic import BaseModel, Field

if TYPE_CHECKING:
    from mcp.server.fastmcp import FastMCP

# MCP ê´€ë ¨ ì„í¬íŠ¸ ì¶”ê°€
mcp_available = False
try:
    # MCP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹œë„
    from mcp.server.fastmcp import FastMCP

    mcp_available = True
    logger = logging.getLogger(__name__)
    logger.info("âœ… MCP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì„±ê³µ")
except ImportError:
    FastMCP = None
    logger = logging.getLogger(__name__)
    logger.warning("âš ï¸ MCP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹¤íŒ¨: MCP ë¹„í™œì„±í™”")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(
    os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
)

# ë¡œì»¬ ëª¨ë“ˆ import
from src.inference.api.handlers import ChatHandler, SpellCheckHandler
from src.inference.api.handlers.google_docs_handler import GoogleDocsHandler
from src.inference.api.handlers.location_handler import LocationHandler
from src.inference.api.handlers.web_search_handler import WebSearchHandler
from src.utils.spellcheck import ModuleStats
from src.shared.prompts import loader as prompt_loader


# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# --- TypedDict ì •ì˜ ---
class ChatCompletionResult(TypedDict):
    response: str
    model: str
    cost: float
    tokens: int
    isComplete: bool | None
    continuationToken: str | None


class SpellCheckResult(TypedDict):
    success: bool
    original_text: str
    corrected_text: str
    errors_found: int
    error_words: list[str]
    accuracy: float
    total_words: int


class WebSearchResultDict(TypedDict):
    title: str
    url: str
    snippet: str
    publishedDate: str | None
    favicon: str | None


class WebSearchAPIResult(TypedDict):
    query: str
    source: str
    num_results: int
    results: list[WebSearchResultDict]
    summary: str
    timestamp: str
    from_cache: bool
    response_time: float


class WebSearchStatsResult(TypedDict):
    total_searches: int
    cache_hits: int
    cache_misses: int
    avg_response_time: float
    last_search_time: str | None
    cache_enabled: bool


# ì „ì—­ ë³€ìˆ˜
openai_client: AsyncOpenAI | None = None
chat_handler: ChatHandler | None = None
spellcheck_handler: SpellCheckHandler | None = None
location_handler: LocationHandler | None = None
web_search_handler: WebSearchHandler | None = None
google_docs_handler: GoogleDocsHandler | None = None
mcp_server: Any = None


@asynccontextmanager
async def lifespan(_app: "FastAPI") -> AsyncGenerator[None, None]:
    """ì„œë²„ ì‹œì‘ ë° ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬"""
    global openai_client, chat_handler, spellcheck_handler, location_handler, web_search_handler, google_docs_handler, mcp_server
    logger.info("ğŸš€ ì„œë²„ ì‹œì‘ ì´ë²¤íŠ¸ ë°œìƒ")

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì™¸ë¶€ API ì—°ë™ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")

    # ë” ê²¬ê³ í•œ HTTP í´ë¼ì´ì–¸íŠ¸ë¥¼ ìœ„í•œ íƒ€ì„ì•„ì›ƒ ì„¤ì •
    timeout = httpx.Timeout(10.0, connect=5.0)
    openai_client = AsyncOpenAI(api_key=api_key, timeout=timeout)
    logger.info("âœ… (Async) OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (íƒ€ì„ì•„ì›ƒ ì„¤ì • ì ìš©)")

    # í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
    chat_handler = ChatHandler(openai_client)
    spellcheck_handler = SpellCheckHandler(openai_client)
    location_handler = LocationHandler()
    web_search_handler = WebSearchHandler(openai_client)
    google_docs_handler = GoogleDocsHandler()

    chat_handler.load_datasets()
    logger.info("âœ… ëª¨ë“  í•¸ë“¤ëŸ¬ ë° ë°ì´í„°ì…‹ ì´ˆê¸°í™” ì™„ë£Œ")

    # MCP ì„œë²„ ì„¤ì •
    if mcp_available and FastMCP is not None:
        try:
            mcp_server = FastMCP("loop_ai", stateless_http=True)
            logger.info("âœ… MCP ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ MCP ì„œë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            mcp_server = None
    yield
    logger.info("ğŸŒ™ ì„œë²„ ì¢…ë£Œ.")


# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Loop AI API",
    description="Loop AI ì°½ì‘ ì§€ì› ì‹œìŠ¤í…œ - ì±„íŒ…, ë§ì¶¤ë²• ê²€ì‚¬, ì‹œë†‰ì‹œìŠ¤ ìƒì„±",
    version="3.0.0",
    lifespan=lifespan,
)


# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Gzip ì••ì¶• ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€: ëª¨ë“  ì‘ë‹µì„ ì••ì¶•í•˜ì—¬ ë„¤íŠ¸ì›Œí¬ ì „ì†¡ëŸ‰ì„ ìµœì†Œí™”í•©ë‹ˆë‹¤.
# minimum_size=1000: 1000ë°”ì´íŠ¸ ì´ìƒì˜ ì‘ë‹µë§Œ ì••ì¶•í•©ë‹ˆë‹¤.
app.add_middleware(GZipMiddleware, minimum_size=1000)


# ë¹„ìš© ì¶”ì 
PRICING_PER_TOKEN = {
    "gpt-4o-mini": {"input": 0.00015 / 1000, "output": 0.0006 / 1000},
    "gpt-4o": {"input": 0.005 / 1000, "output": 0.015 / 1000},
    "gpt-3.5-turbo": {"input": 0.0005 / 1000, "output": 0.0015 / 1000},
}

monthly_usage = {"cost": 0.0, "tokens": 0}
MONTHLY_BUDGET = float(os.getenv("OPENAI_MONTHLY_BUDGET", "15.0"))

# LRU ìºì‹œ ì œë„¤ë¦­ íƒ€ì… ì •ì˜
K = TypeVar("K")
V = TypeVar("V")


# LRU ìºì‹œ êµ¬í˜„
class LRUCache(Generic[K, V]):
    def __init__(self, capacity: int = 1024):
        self.cache: OrderedDict[K, V] = OrderedDict()
        self.capacity: int = capacity

    def get(self, key: K) -> V | None:
        if key not in self.cache:
            return None
        self.cache.move_to_end(key)
        return self.cache[key]

    def put(self, key: K, value: V) -> None:
        if key in self.cache:
            self.cache.move_to_end(key)
        elif len(self.cache) >= self.capacity:
            _ = self.cache.popitem(last=False)
        self.cache[key] = value


response_cache: LRUCache[str, str] = LRUCache()


# API ëª¨ë¸ ì •ì˜
class ChatMessage(BaseModel):
    role: str = Field(..., description="ë©”ì‹œì§€ ì—­í•  (user/assistant)")
    content: str = Field(..., description="ë©”ì‹œì§€ ë‚´ìš©")


class ChatRequest(BaseModel):
    message: str = Field(..., description="ì‚¬ìš©ì ë©”ì‹œì§€")
    history: list[ChatMessage] = Field(default=[], description="ì±„íŒ… íˆìŠ¤í† ë¦¬")
    model: str | None = Field(None, description="ì‚¬ìš©í•  ëª¨ë¸")
    maxTokens: int = Field(4000, description="ìµœëŒ€ í† í° ìˆ˜")
    isLongForm: bool = Field(False, description="ê¸´ í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë“œ")
    continueStory: bool = Field(False, description="ì´ì•¼ê¸° ê³„ì†í•˜ê¸° ëª¨ë“œ")


class ChatResponse(BaseModel):
    response: str = Field(..., description="AI ì‘ë‹µ")
    model: str = Field(..., description="ì‚¬ìš©ëœ ëª¨ë¸")
    cost: float = Field(..., description="ë¹„ìš© (USD)")
    tokens: int = Field(..., description="ì‚¬ìš©ëœ í† í° ìˆ˜")
    isComplete: bool | None = Field(True, description="ì‘ë‹µ ì™„ë£Œ ì—¬ë¶€")


class SpellCheckRequest(BaseModel):
    text: str = Field(..., description="ë§ì¶¤ë²• ê²€ì‚¬í•  í…ìŠ¤íŠ¸")
    auto_correct: bool = Field(default=True, description="ìë™ ìˆ˜ì • ì—¬ë¶€")
    # AI ê¸°ë°˜ êµì •ì„ ìœ„í•œ í•„ë“œ ì¶”ê°€
    full_document: str | None = Field(None, description="ì „ì²´ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸")
    use_ai: bool = Field(default=False, description="AI ê¸°ë°˜ ë¬¸ë§¥ êµì • ì‚¬ìš© ì—¬ë¶€")


class SpellCheckResponse(BaseModel):
    original_text: str = Field(..., description="ì›ë³¸ í…ìŠ¤íŠ¸")
    corrected_text: str = Field(..., description="ìˆ˜ì •ëœ í…ìŠ¤íŠ¸")
    errors_found: int = Field(..., description="ë°œê²¬ëœ ì˜¤íƒ€ ìˆ˜")
    error_words: list[str] = Field(..., description="ì˜¤íƒ€ ë‹¨ì–´ ëª©ë¡")
    accuracy: float = Field(..., description="ì •í™•ë„ (%)")
    total_words: int = Field(..., description="ì´ ë‹¨ì–´ ìˆ˜")
    # AI ê¸°ë°˜ êµì • ê²°ê³¼ë¥¼ ìœ„í•œ í•„ë“œ ì¶”ê°€
    reason: str | None = Field(None, description="AI êµì • ì´ìœ ")
    context_analysis: str | None = Field(None, description="AI ë¬¸ë§¥ ë¶„ì„ ê²°ê³¼")


class CostStatusResponse(BaseModel):
    monthly_cost: float
    monthly_budget: float
    usage_percentage: float
    total_tokens: int
    cache_hits: int


class LocationSuggestRequest(BaseModel):
    query: str = Field(..., description="ì¶”ì²œì„ ìœ„í•œ ê²€ìƒ‰ì–´ (ë„ì‹œ/ì§€ì—­ëª…)")


class LocationSuggestResponse(BaseModel):
    suggestions: list[str] = Field(..., description="ì¶”ì²œëœ ì§€ì—­Â·ë„ì‹œëª… ëª©ë¡")


class WebSearchRequest(BaseModel):
    query: str = Field(..., description="ê²€ìƒ‰ì–´")
    source: str = Field(
        default="web", description="ê²€ìƒ‰ ì†ŒìŠ¤ (web, research, wiki, github, company)"
    )
    num_results: int = Field(default=5, ge=1, le=10, description="ê²°ê³¼ ê°œìˆ˜ (1-10)")
    include_summary: bool = Field(default=True, description="AI ìš”ì•½ í¬í•¨ ì—¬ë¶€")


class WebSearchResult(BaseModel):
    title: str
    url: str
    snippet: str
    publishedDate: str | None = None
    favicon: str | None = None


class WebSearchResponse(BaseModel):
    query: str
    source: str
    num_results: int
    results: list[WebSearchResult]
    summary: str = ""
    timestamp: str
    from_cache: bool = False
    response_time: float


class WebSearchStatsResponse(BaseModel):
    total_searches: int
    cache_hits: int
    cache_misses: int
    avg_response_time: float
    last_search_time: str | None
    cache_enabled: bool


def calculate_cost(prompt_tokens: int, completion_tokens: int, model: str) -> float:
    """í† í° ì‚¬ìš©ëŸ‰ì— ë”°ë¥¸ ë¹„ìš© ê³„ì‚°"""
    model_pricing = PRICING_PER_TOKEN.get(model, {"input": 0, "output": 0})
    cost = (
        prompt_tokens * model_pricing["input"]
        + completion_tokens * model_pricing["output"]
    )
    monthly_usage["cost"] += cost
    monthly_usage["tokens"] += prompt_tokens + completion_tokens
    return cost


@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {"message": "Loop AI ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤."}


@app.post("/api/chat")
async def chat_endpoint(request: ChatRequest) -> StreamingResponse:
    """
    ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    if not chat_handler or not openai_client:
        raise HTTPException(
            status_code=503,
            detail="ì„œë²„ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        )

    try:
        # 1. ì‚¬ìš©ì ì˜ë„ ë° ë ˆë²¨ íŒŒì•…
        intent, level = chat_handler.detect_intent_and_level(request.message)

        # 2. ì˜ë„ì— ë”°ë¥¸ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„± ë˜ëŠ” í•¸ë“¤ëŸ¬ í˜¸ì¶œ
        if intent == "web_search":
            generator = chat_handler.handle_web_search(request.message)
        else:
            # 2a. í”„ë¡¬í”„íŠ¸ ìƒì„± (intentê°€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì´ë¦„ê³¼ ì¼ì¹˜í•œë‹¤ê³  ê°€ì •)
            prompt = prompt_loader.get_prompt(
                intent, user_message=request.message, level=level
            )
            # 2b. í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
            generator = chat_handler.generate_response(
                prompt=prompt,
                max_tokens=request.maxTokens,
                temperature=0.7,
            )
        
        # 3. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°˜í™˜
        return StreamingResponse(generator, media_type="text/event-stream")

    except ValueError as e:
        logger.error(f"í”„ë¡¬í”„íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except APIConnectionError as e:
        logger.error(f"OpenAI API ì—°ê²° ì˜¤ë¥˜: {e.__cause__}")
        raise HTTPException(
            status_code=503, detail="ì™¸ë¶€ API ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    except Exception as e:
        logger.exception(f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


@app.post("/api/spellcheck", response_model=SpellCheckResponse)
async def spellcheck_endpoint(request: SpellCheckRequest) -> SpellCheckResponse:
    """ë§ì¶¤ë²• ê²€ì‚¬ ì—”ë“œí¬ì¸íŠ¸"""
    if not spellcheck_handler:
        raise HTTPException(
            status_code=503,
            detail="ì„œë²„ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        )

    try:
        if request.use_ai and request.full_document:
            # AI ê¸°ë°˜ ë¬¸ë§¥ êµì •
            result = await spellcheck_handler.context_aware_correction(
                target_text=request.text, full_document=request.full_document
            )
        else:
            # ê¸°ì¡´ ë¡œì»¬ êµì •
            result = spellcheck_handler.create_spellcheck_response(
                request.text, request.auto_correct
            )
        
        # TypedDictì—ì„œ Pydantic ëª¨ë¸ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
        return SpellCheckResponse(
            original_text=result.get("original_text", request.text),
            corrected_text=result.get("corrected_text", request.text),
            errors_found=result.get("errors_found", 0),
            error_words=result.get("error_words", []),
            accuracy=result.get("accuracy", 100.0),
            total_words=result.get("total_words", 0),
            reason=result.get("reason"),
            context_analysis=result.get("context_analysis"),
        )

    except Exception as e:
        logger.exception(f"ë§ì¶¤ë²• ê²€ì‚¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/cost-status", response_model=CostStatusResponse)
async def get_cost_status():
    """ì›”ë³„ ë¹„ìš© ì‚¬ìš© í˜„í™© ì¡°íšŒ"""
    cost = monthly_usage["cost"]
    tokens = monthly_usage["tokens"]
    usage_percentage = (cost / MONTHLY_BUDGET) * 100 if MONTHLY_BUDGET > 0 else 0

    return CostStatusResponse(
        monthly_cost=round(cost, 4),
        monthly_budget=MONTHLY_BUDGET,
        usage_percentage=round(usage_percentage, 2),
        total_tokens=int(tokens),
        cache_hits=response_cache.capacity - len(response_cache.cache),
    )


@app.get("/api/spellcheck/stats")
async def get_spellcheck_stats() -> ModuleStats:
    """ë§ì¶¤ë²• ê²€ì‚¬ê¸° í†µê³„ ì¡°íšŒ"""
    if not spellcheck_handler:
        raise HTTPException(status_code=503, detail="ë§ì¶¤ë²• ê²€ì‚¬ê¸° ì¤€ë¹„ ì•ˆë¨")
    return spellcheck_handler.get_statistics()


@app.get("/api/health")
async def health_check():
    """
    ì„œë²„ì˜ ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤.
    - OpenAI API ì—°ê²° ìƒíƒœ í™•ì¸
    - í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” ì—¬ë¶€ í™•ì¸
    """
    status = {"status": "ok", "timestamp": datetime.now(timezone.utc).isoformat()}
    details = {}

    # OpenAI ì—°ê²° ìƒíƒœ í™•ì¸
    if openai_client:
        try:
            _ = await openai_client.models.list(timeout=5)
            details["openai_api"] = "connected"
        except Exception as e:
            details["openai_api"] = f"disconnected: {e}"
            status["status"] = "error"
    else:
        details["openai_api"] = "not_initialized"
        status["status"] = "error"

    # í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” í™•ì¸
    details["chat_handler"] = "initialized" if chat_handler else "not_initialized"
    if not chat_handler:
        status["status"] = "error"
        
    if status["status"] == "ok":
        return status
    else:
        raise HTTPException(status_code=503, detail=details)


@app.post("/api/location-suggest", response_model=LocationSuggestResponse)
async def suggest_locations(request: LocationSuggestRequest) -> LocationSuggestResponse:
    """ì§€ì—­/ë„ì‹œëª… ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸"""
    if not location_handler:
        raise HTTPException(status_code=503, detail="Location handler not ready")

    suggestions = location_handler.suggest_locations(request.query)
    return LocationSuggestResponse(suggestions=suggestions)


@app.post("/api/web-search", response_model=WebSearchResponse)
async def web_search(request: WebSearchRequest) -> WebSearchResponse:
    """ì›¹ ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸"""
    if not web_search_handler:
        raise HTTPException(status_code=503, detail="Web search handler not ready")

    start_time = time.time()
    # search ë©”ì„œë“œëŠ” (summary, results_list) íŠœí”Œì„ ë°˜í™˜
    summary, search_results = await web_search_handler.search(
        query=request.query,
        source=request.source,
        num_results=request.num_results,
        include_summary=request.include_summary,
    )
    end_time = time.time()

    # WebSearchResult ëª¨ë¸ë¡œ ë³€í™˜
    validated_results = [WebSearchResult(**r) for r in search_results]

    return WebSearchResponse(
        query=request.query, # ìš”ì²­ì—ì„œ queryë¥¼ ê°€ì ¸ì˜´
        source=request.source, # ìš”ì²­ì—ì„œ sourceë¥¼ ê°€ì ¸ì˜´
        num_results=len(validated_results),
        results=validated_results,
        summary=summary,
        timestamp=datetime.fromtimestamp(start_time).isoformat(),
        from_cache=False, # TODO: ìºì‹œ ë¡œì§ê³¼ ì—°ë™ í•„ìš”
        response_time=(end_time - start_time),
    )


@app.get("/api/web-search/stats", response_model=WebSearchStatsResponse)
async def get_web_search_stats() -> WebSearchStatsResponse:
    """ì›¹ ê²€ìƒ‰ í†µê³„ ì¡°íšŒ"""
    if not web_search_handler:
        raise HTTPException(status_code=503, detail="Web search handler not ready")
    stats = web_search_handler.get_statistics()
    # TypedDictë¥¼ Pydantic ëª¨ë¸ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
    return WebSearchStatsResponse(
        total_searches=stats.get("total_searches", 0),
        cache_hits=stats.get("cache_hits", 0),
        cache_misses=stats.get("cache_misses", 0),
        avg_response_time=stats.get("avg_response_time", 0.0),
        last_search_time=stats.get("last_search_time"),
        cache_enabled=stats.get("cache_enabled", False),
    )


@app.delete("/api/web-search/cache")
async def clear_web_search_cache():
    """ì›¹ ê²€ìƒ‰ ìºì‹œ ì‚­ì œ"""
    if not web_search_handler:
        raise HTTPException(status_code=503, detail="Web search handler not ready")
    _ = await web_search_handler.clear_cache()
    return {"message": "Web search cache cleared successfully."}


@app.post("/api/clear_cache")
async def clear_cache_endpoint():
    """
    ì„œë²„ì˜ ëª¨ë“  ìºì‹œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
    """
    if chat_handler:
        _ = chat_handler.clear_cache()
    if web_search_handler:
        _ = await web_search_handler.clear_cache()
    response_cache.cache.clear()
    logger.info("ëª¨ë“  ì„œë²„ ìºì‹œê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
    return {"message": "All server caches cleared successfully."}


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
