# 🚀 Loop AI 토큰 최적화 가이드

## 📋 개요
소설 생성 시 토큰 제한으로 인해 중간에 끊어지는 문제를 해결하고, 토큰을 절약하면서도 긴 텍스트를 생성할 수 있는 최적화 전략을 제공합니다.

## 🔧 주요 개선사항

### 1. **Next.js API 응답 크기 제한 해제**
```typescript
// frontend/src/app/api/chat/route.ts
export const config = {
  api: {
    responseLimit: '10mb', // 10MB로 제한 증가
  },
}
```

### 2. **동적 토큰 할당 시스템**
- **초보자**: 800-2000 토큰
- **중급자**: 1200-3000 토큰  
- **고급자**: 2000-4000 토큰
- **긴 소설 모드**: 최대 8000 토큰

### 3. **긴 소설 모드 (Long Form Mode)**
- 더 풍부한 묘사와 세부사항
- 캐릭터 내면 심리 깊이 있게 표현
- 장면 전환과 분위기 조성 강화
- 독자 몰입도 향상

### 4. **이야기 계속하기 기능**
- 미완성 응답 감지
- 자동 계속하기 버튼 표시
- 맥락 유지하며 이어쓰기
- 스토리 일관성 보장

## 🎯 토큰 절약 전략

### 1. **효율적인 프롬프트 설계**
```
✅ 좋은 예:
"판타지 소설의 첫 장을 써주세요. 주인공은 마법사입니다."

❌ 나쁜 예:
"안녕하세요. 저는 판타지 소설을 좋아하는 독자입니다. 혹시 시간이 되신다면 마법사가 주인공인 판타지 소설의 첫 번째 장을 작성해주실 수 있을까요? 가능하다면 흥미진진하고 재미있게 써주시면 감사하겠습니다."
```

### 2. **핵심 정보 집중**
- 불필요한 반복 피하기
- 간결하면서도 임팩트 있는 표현
- 효율적인 문장 구조로 정보 밀도 높이기
- 중요한 내용 우선 배치

### 3. **히스토리 관리**
- 최근 10개 메시지만 유지
- 오래된 대화 자동 정리
- 핵심 맥락만 보존

### 4. **모델별 최적화**
```typescript
// 모델별 토큰 효율성
gpt-4o-mini: {
  input: $0.00015/1K tokens,  // 가장 경제적
  output: $0.0006/1K tokens,
  권장: 일반적인 창작
}

gpt-4o: {
  input: $0.005/1K tokens,    // 고품질
  output: $0.015/1K tokens,
  권장: 전문적인 작품
}
```

## 🛠️ 사용법

### 1. **긴 소설 모드 활성화**
1. 우측 하단 "설정" 버튼 클릭
2. "긴 소설 모드" 토글 ON
3. 토큰 수 슬라이더로 조정 (1K-8K)
4. 메시지 전송

### 2. **토큰 수 조정**
- **1K (짧게)**: 빠른 아이디어, 간단한 답변
- **4K (보통)**: 일반적인 소설 생성
- **8K (길게)**: 긴 소설, 상세한 묘사

### 3. **이야기 계속하기**
- AI 응답 옆에 🔄 버튼이 나타나면 클릭
- "이야기를 계속 써주세요" 자동 전송
- 이전 맥락을 유지하며 이어서 작성

## 📊 비용 최적화

### 1. **실시간 비용 모니터링**
```typescript
// 헤더에 실시간 비용 표시
<div className="bg-blue-50 rounded-full">
  <Zap className="w-4 h-4 text-blue-600" />
  <span>$0.0234</span>
</div>
```

### 2. **예산 관리**
- 월 예산 설정: `OPENAI_MONTHLY_BUDGET=15.0`
- 사용량 추적 및 알림
- 예산 초과 시 자동 제한

### 3. **캐싱 활용**
- LRU 캐시로 중복 요청 방지
- 자주 사용되는 응답 재활용
- 네트워크 비용 절약

## 🎨 UI/UX 개선사항

### 1. **직관적인 토큰 표시**
```tsx
{/* 토큰 수 표시 */}
<div className="bg-gray-100 text-gray-600 rounded-full text-xs">
  <Zap className="w-3 h-3" />
  {maxTokens.toLocaleString()} 토큰
</div>
```

### 2. **모드 상태 표시**
```tsx
{/* 긴 소설 모드 표시 */}
{isLongFormMode && (
  <div className="bg-purple-100 text-purple-700 rounded-full text-xs">
    <BookOpen className="w-3 h-3" />
    긴 소설 모드
  </div>
)}
```

### 3. **진행 상태 피드백**
- 로딩 중 상세한 상태 메시지
- 토큰 사용량 실시간 업데이트
- 완료/미완료 상태 명확히 표시

## 🔍 성능 최적화

### 1. **응답 시간 개선**
- 30초 타임아웃 설정
- 점진적 백오프 재시도
- AbortController로 안전한 취소

### 2. **메모리 관리**
- 메시지 히스토리 제한
- 자동 가비지 컬렉션
- 캐시 크기 제한

### 3. **네트워크 최적화**
- 압축된 요청/응답
- 중복 요청 방지
- 효율적인 데이터 구조

## 📈 모니터링 및 분석

### 1. **토큰 사용량 추적**
```typescript
const [totalCost, setTotalCost] = useState(0)
const [tokenUsage, setTokenUsage] = useState({
  input: 0,
  output: 0,
  total: 0
})
```

### 2. **성능 메트릭**
- 응답 시간
- 토큰 효율성
- 사용자 만족도
- 에러율

### 3. **사용 패턴 분석**
- 인기 있는 요청 유형
- 평균 토큰 사용량
- 피크 사용 시간
- 비용 트렌드

## 🚨 주의사항

### 1. **토큰 제한**
- OpenAI 모델별 최대 토큰 수 준수
- 컨텍스트 윈도우 초과 시 자동 조정
- 긴 텍스트는 여러 번에 나누어 생성

### 2. **비용 관리**
- 예상 비용 미리 확인
- 예산 초과 방지 시스템
- 정기적인 사용량 검토

### 3. **품질 vs 비용**
- 토큰 수와 품질의 균형
- 목적에 맞는 모델 선택
- 불필요한 기능 비활성화

## 🎯 실제 사용 예시

### 예시 1: 짧은 소설 (2K 토큰)
```
요청: "로맨스 단편소설 써줘"
설정: 일반 모드, 2000 토큰
결과: 약 1500자 분량의 완성된 단편
비용: ~$0.003
```

### 예시 2: 긴 소설 (6K 토큰)
```
요청: "판타지 소설 첫 장을 자세히 써줘"
설정: 긴 소설 모드, 6000 토큰
결과: 약 4000자 분량의 상세한 첫 장
비용: ~$0.012
```

### 예시 3: 이어쓰기 (4K 토큰)
```
요청: "이야기를 계속 써주세요"
설정: 계속하기 모드, 4000 토큰
결과: 이전 맥락을 유지한 자연스러운 연결
비용: ~$0.008
```

## 🔗 관련 문서

- [QA_TEST_SCENARIOS.md](./QA_TEST_SCENARIOS.md) - 테스트 시나리오
- [OpenAI API 문서](https://platform.openai.com/docs) - 공식 API 가이드
- [Next.js 응답 크기 제한](https://nextjs.org/docs/messages/api-routes-response-size-limit) - Next.js 설정

---

**💡 팁**: 토큰을 절약하면서도 품질 좋은 소설을 생성하려면, 명확하고 구체적인 요청을 하고, 긴 소설 모드를 적절히 활용하세요! 