# API ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

Loop AI API ì‚¬ìš© ì¤‘ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œë“¤ê³¼ í•´ê²° ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨
- [ì—°ê²° ë¬¸ì œ](#ì—°ê²°-ë¬¸ì œ)
- [Fantasy Name Generator ë¬¸ì œ](#fantasy-name-generator-ë¬¸ì œ)
- [Story Generator ë¬¸ì œ](#story-generator-ë¬¸ì œ)
- [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
- [ì—ëŸ¬ ì½”ë“œ ê°€ì´ë“œ](#ì—ëŸ¬-ì½”ë“œ-ê°€ì´ë“œ)
- [ë””ë²„ê¹… ë„êµ¬](#ë””ë²„ê¹…-ë„êµ¬)

## ğŸ”Œ ì—°ê²° ë¬¸ì œ

### 1. ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤

**ì¦ìƒ:**
```
ConnectionError: Failed to establish a new connection
```

**ì›ì¸ ë° í•´ê²°ë°©ë²•:**

1. **ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸**
   ```bash
   # ì„œë²„ ìƒíƒœ í™•ì¸
   curl http://localhost:8000/api/health
   
   # ì„œë²„ ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)
   python src/inference/server.py &
   ```

2. **í¬íŠ¸ ì¶©ëŒ í™•ì¸**
   ```bash
   # 8000ë²ˆ í¬íŠ¸ ì‚¬ìš© í”„ë¡œì„¸ìŠ¤ í™•ì¸
   lsof -i :8000
   
   # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ í›„ ì¬ì‹œì‘
   kill -9 <PID>
   python src/inference/server.py
   ```

3. **ë°©í™”ë²½ ì„¤ì • í™•ì¸**
   ```bash
   # macOS ë°©í™”ë²½ í™•ì¸
   sudo pfctl -sr | grep 8000
   
   # Windows ë°©í™”ë²½ í™•ì¸
   netsh advfirewall firewall show rule name="Port 8000"
   ```

### 2. CORS ì—ëŸ¬

**ì¦ìƒ:**
```
Access to XMLHttpRequest has been blocked by CORS policy
```

**í•´ê²°ë°©ë²•:**

1. **ì„œë²„ ì„¤ì • í™•ì¸** (`src/inference/server.py`)
   ```python
   from fastapi.middleware.cors import CORSMiddleware
   
   app.add_middleware(
       CORSMiddleware,
       allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” êµ¬ì²´ì ì¸ ë„ë©”ì¸ ì§€ì •
       allow_credentials=True,
       allow_methods=["*"],
       allow_headers=["*"],
   )
   ```

2. **í”„ë¡ì‹œ ì„¤ì •** (ê°œë°œ í™˜ê²½)
   ```javascript
   // package.json (React)
   "proxy": "http://localhost:8000"
   
   // ë˜ëŠ” axios ì„¤ì •
   axios.defaults.baseURL = 'http://localhost:8000';
   ```

## ğŸ­ Fantasy Name Generator ë¬¸ì œ

### 1. ê°™ì€ ì´ë¦„ì´ ë°˜ë³µ ìƒì„±ë¨

**ì¦ìƒ:**
ë™ì¼í•œ íŒŒë¼ë¯¸í„°ë¡œ ìš”ì²­ ì‹œ ê³„ì† ê°™ì€ ì´ë¦„ì´ ë‚˜ì˜´

**í•´ê²°ë°©ë²•:**

1. **ìŠ¤íƒ€ì¼ ë³€ê²½**
   ```bash
   curl -X POST "http://localhost:8000/api/names/generate" \
     -H "Content-Type: application/json" \
     -d '{
       "style": "mixed",  # "anime" ëŒ€ì‹  "mixed" ì‚¬ìš©
       "count": 5
     }'
   ```

2. **íŒŒë¼ë¯¸í„° ì¡°í•©**
   ```python
   # ë‹¤ì–‘í•œ ì¡°í•©ìœ¼ë¡œ ìƒì„±
   params_list = [
       {"gender": "female", "style": "anime", "character_class": "ë§ˆë²•ì‚¬"},
       {"gender": "female", "style": "western", "element": "fire"},
       {"gender": "female", "style": "composed"},
   ]
   
   for params in params_list:
       response = requests.post(url, json=params)
   ```

### 2. ì›í•˜ì§€ ì•ŠëŠ” ì„±ë³„ì˜ ì´ë¦„ ìƒì„±

**ì¦ìƒ:**
`gender: "male"`ë¡œ ì„¤ì •í–ˆëŠ”ë° ì—¬ì„± ì´ë¦„ì´ ë‚˜ì˜´

**í•´ê²°ë°©ë²•:**

1. **ëª…ì‹œì  ì„±ë³„ ì§€ì •**
   ```json
   {
     "gender": "male",
     "style": "western",  // ì„œì–‘ ìŠ¤íƒ€ì¼ì€ ì„±ë³„ êµ¬ë¶„ì´ ë” ëª…í™•
     "character_class": "ê¸°ì‚¬"
   }
   ```

2. **í›„ì²˜ë¦¬ í•„í„°ë§**
   ```python
   def filter_by_gender(names, target_gender):
       # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± í•„í„°ë§
       male_endings = ['ìŠ¤', 'íŠ¸', 'ë“œ', 'ë¥´', 'ì˜¨']
       female_endings = ['ì•„', 'ë‚˜', 'ë¦¬', 'ë¯¸', 'ì‚¬']
       
       filtered = []
       for name_obj in names:
           name = name_obj['name']
           if target_gender == 'male' and name[-1] in male_endings:
               filtered.append(name_obj)
           elif target_gender == 'female' and name[-1] in female_endings:
               filtered.append(name_obj)
       
       return filtered
   ```

### 3. ì›ì†Œ ì†ì„±ì´ ë°˜ì˜ë˜ì§€ ì•ŠìŒ

**ì¦ìƒ:**
`element: "fire"`ë¡œ ì„¤ì •í–ˆëŠ”ë° ë¶ˆê³¼ ê´€ë ¨ ì—†ëŠ” ì´ë¦„ì´ ë‚˜ì˜´

**í•´ê²°ë°©ë²•:**

1. **í´ë˜ìŠ¤ì™€ ì›ì†Œ ì¡°í•©**
   ```bash
   curl -X POST "http://localhost:8000/api/names/generate" \
     -H "Content-Type: application/json" \
     -d '{
       "character_class": "ë§ˆë²•ì‚¬",
       "element": "fire",
       "count": 5
     }'
   ```

2. **ì›ì†Œ ëª©ë¡ í™•ì¸**
   ```bash
   # ì‚¬ìš© ê°€ëŠ¥í•œ ì›ì†Œ í™•ì¸
   curl http://localhost:8000/api/names/elements
   ```

## ğŸ“– Story Generator ë¬¸ì œ

### 1. ë„ˆë¬´ ì§§ì€ ìŠ¤í† ë¦¬ ìƒì„±

**ì¦ìƒ:**
1-2 ë¬¸ì¥ë§Œ ìƒì„±ë˜ê³  ëë‚¨

**í•´ê²°ë°©ë²•:**

1. **í† í° ìˆ˜ ì¦ê°€**
   ```python
   response = requests.post(url, json={
       "prompt": "ìƒì„¸í•˜ê³  ê¸´ ì´ì•¼ê¸°ë¥¼ ì¨ì¤˜",
       "max_new_tokens": 800,  # ê¸°ë³¸ê°’ 512ë³´ë‹¤ ì¦ê°€
       "temperature": 0.7
   })
   ```

2. **í”„ë¡¬í”„íŠ¸ ê°œì„ **
   ```python
   # ë‚˜ìœ ì˜ˆ
   prompt = "ì´ì•¼ê¸° ì¨ì¤˜"
   
   # ì¢‹ì€ ì˜ˆ  
   prompt = """
   ë§ˆë²•í•™êµì— ì…í•™í•œ ì£¼ì¸ê³µì´ ì²« ì‹œí—˜ì—ì„œ ì˜ˆìƒì¹˜ ëª»í•œ ëŠ¥ë ¥ì„ ë°œê²¬í•˜ê³ ,
   ì´ë¡œ ì¸í•´ ë²Œì–´ì§€ëŠ” ëª¨í—˜ì„ ìì„¸íˆ ì¨ì¤˜. 
   ë“±ì¥ì¸ë¬¼ë“¤ì˜ ì‹¬ë¦¬ ë¬˜ì‚¬ì™€ ë§ˆë²• ì‹œìŠ¤í…œì— ëŒ€í•œ ì„¤ëª…ë„ í¬í•¨í•´ì¤˜.
   """
   ```

### 2. ë°˜ë³µì ì¸ ë‚´ìš© ìƒì„±

**ì¦ìƒ:**
ê°™ì€ ë¬¸ì¥ì´ë‚˜ ë‹¨ì–´ê°€ ê³„ì† ë°˜ë³µë¨

**í•´ê²°ë°©ë²•:**

1. **ì˜¨ë„ ì¡°ì •**
   ```python
   # ë°˜ë³µì´ ì‹¬í•  ë•Œ
   params = {
       "temperature": 0.8,  # 0.5ì—ì„œ 0.8ë¡œ ì¦ê°€
       "max_new_tokens": 500
   }
   ```

2. **í”„ë¡¬í”„íŠ¸ ë‹¤ì–‘í™”**
   ```python
   # ë§¤ë²ˆ ë‹¤ë¥¸ ì‹œì‘ì  ì œê³µ
   import random
   
   starters = [
       "ê°‘ìê¸°",
       "ê·¸ë•Œì˜€ë‹¤",
       "í•˜ì§€ë§Œ",
       "í•œí¸",
       "ë†€ëê²Œë„"
   ]
   
   prompt = f"{random.choice(starters)}, {original_prompt}"
   ```

### 3. ì˜ëª»ëœ ì¥ë¥´ì˜ ë‚´ìš© ìƒì„±

**ì¦ìƒ:**
`genre: "romance"`ì¸ë° ì•¡ì…˜ ì¥ë©´ì´ ë‚˜ì˜´

**í•´ê²°ë°©ë²•:**

1. **ì¥ë¥´ í‚¤ì›Œë“œ í¬í•¨**
   ```python
   genre_keywords = {
       "romance": "ì‚¬ë‘, ê°ì •, ë§ˆìŒ, ì„¤ë ˜, ì—°ì¸",
       "fantasy": "ë§ˆë²•, ëª¨í—˜, ìš©, ë§ˆë²•ì‚¬, ì™•êµ­",
       "sf": "ë¯¸ë˜, ë¡œë´‡, ìš°ì£¼, ê¸°ìˆ , ê³¼í•™",
       "mystery": "ìˆ˜ìˆ˜ê»˜ë¼, ë‹¨ì„œ, ì¶”ë¦¬, ë²”ì¸, ë¹„ë°€"
   }
   
   prompt = f"{original_prompt}. {genre_keywords[genre]} ìš”ì†Œë¥¼ í¬í•¨í•´ì„œ ì¨ì¤˜."
   ```

2. **ì¥ë¥´ë³„ ìµœì  ì„¤ì • ì‚¬ìš©**
   ```python
   genre_settings = {
       "fantasy": {"temperature": 0.8, "max_new_tokens": 600},
       "romance": {"temperature": 0.7, "max_new_tokens": 500},
       "sf": {"temperature": 0.6, "max_new_tokens": 700},
       "mystery": {"temperature": 0.5, "max_new_tokens": 600}
   }
   
   settings = genre_settings.get(genre, {"temperature": 0.7, "max_new_tokens": 500})
   ```

## ğŸš€ ì„±ëŠ¥ ìµœì í™”

### 1. ëŠë¦° ì‘ë‹µ ì‹œê°„

**ë¬¸ì œ ì§„ë‹¨:**

1. **ì„œë²„ ë¦¬ì†ŒìŠ¤ í™•ì¸**
   ```bash
   # CPU ì‚¬ìš©ë¥  í™•ì¸
   top -p $(pgrep -f "python.*server.py")
   
   # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
   ps aux | grep "python.*server.py"
   
   # GPU ì‚¬ìš©ëŸ‰ í™•ì¸ (CUDA í™˜ê²½)
   nvidia-smi
   ```

2. **ëª¨ë¸ ë¡œë”© ìƒíƒœ í™•ì¸**
   ```python
   # í—¬ìŠ¤ì²´í¬ë¡œ ëª¨ë¸ ìƒíƒœ í™•ì¸
   import requests
   response = requests.get("http://localhost:8000/api/health")
   print(response.json())
   ```

**ìµœì í™” ë°©ë²•:**

1. **ë°°ì¹˜ ì²˜ë¦¬**
   ```python
   # ë‚˜ìœ ì˜ˆ: ìˆœì°¨ ì²˜ë¦¬
   for i in range(10):
       response = requests.post(url, json={"count": 1})
   
   # ì¢‹ì€ ì˜ˆ: ë°°ì¹˜ ì²˜ë¦¬
   response = requests.post(url, json={"count": 10})
   ```

2. **ëª¨ë¸ ìºì‹±**
   ```python
   # ì„œë²„ì—ì„œ ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë“œí•˜ë„ë¡ í™•ì¸
   # src/inference/server.py í™•ì¸
   ```

### 2. ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì¦ìƒ:**
```
CUDA out of memory
RuntimeError: out of memory
```

**í•´ê²°ë°©ë²•:**

1. **í† í° ìˆ˜ ì¤„ì´ê¸°**
   ```python
   # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
   params = {
       "max_new_tokens": 300,  # ê¸°ë³¸ê°’ì„ ë‚®ì¶¤
       "temperature": 0.7
   }
   ```

2. **ë°°ì¹˜ í¬ê¸° ì¡°ì •**
   ```python
   # í•œ ë²ˆì— ë§ì€ ì´ë¦„ì„ ìƒì„±í•˜ì§€ ë§ê³  ë‚˜ëˆ„ì–´ì„œ ì²˜ë¦¬
   def generate_large_batch(total_count):
       batch_size = 5
       all_names = []
       
       for i in range(0, total_count, batch_size):
           current_batch = min(batch_size, total_count - i)
           response = requests.post(url, json={"count": current_batch})
           all_names.extend(response.json()['names'])
           
           time.sleep(0.5)  # ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œê°„
       
       return all_names
   ```

## ğŸ“Š ì—ëŸ¬ ì½”ë“œ ê°€ì´ë“œ

### HTTP 400 - Bad Request

**ì¼ë°˜ì ì¸ ì›ì¸:**

1. **í•„ìˆ˜ íŒŒë¼ë¯¸í„° ëˆ„ë½**
   ```python
   # ì˜ëª»ëœ ìš”ì²­
   response = requests.post(url, json={})  # prompt ëˆ„ë½
   
   # ì˜¬ë°”ë¥¸ ìš”ì²­
   response = requests.post(url, json={"prompt": "ì´ì•¼ê¸°ë¥¼ ì¨ì¤˜"})
   ```

2. **ì˜ëª»ëœ íŒŒë¼ë¯¸í„° ê°’**
   ```python
   # ì˜ëª»ëœ ê°’
   {
       "temperature": 2.0,  # ìµœëŒ€ê°’ 1.0 ì´ˆê³¼
       "max_new_tokens": 2000,  # ìµœëŒ€ê°’ 1000 ì´ˆê³¼
       "genre": "invalid_genre"  # ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¥ë¥´
   }
   
   # ì˜¬ë°”ë¥¸ ê°’
   {
       "temperature": 0.8,
       "max_new_tokens": 500,
       "genre": "fantasy"
   }
   ```

### HTTP 422 - Unprocessable Entity

**í•´ê²°ë°©ë²•:**

1. **íŒŒë¼ë¯¸í„° íƒ€ì… í™•ì¸**
   ```python
   # ì˜ëª»ëœ íƒ€ì…
   {
       "count": "5",  # ë¬¸ìì—´ ëŒ€ì‹  ìˆ«ì í•„ìš”
       "temperature": "0.7"
   }
   
   # ì˜¬ë°”ë¥¸ íƒ€ì…
   {
       "count": 5,
       "temperature": 0.7
   }
   ```

2. **ë²”ìœ„ í™•ì¸**
   ```python
   # ë²”ìœ„ ì´ˆê³¼
   {
       "count": 25,  # ìµœëŒ€ 20
       "temperature": -0.1  # ìµœì†Œ 0.1
   }
   ```

### HTTP 500 - Internal Server Error

**ì§„ë‹¨ ë° í•´ê²°:**

1. **ì„œë²„ ë¡œê·¸ í™•ì¸**
   ```bash
   tail -f server.log
   ```

2. **ëª¨ë¸ ìƒíƒœ í™•ì¸**
   ```bash
   # ì„œë²„ ì¬ì‹œì‘
   pkill -f "python.*server.py"
   python src/inference/server.py > server.log 2>&1 &
   ```

## ğŸ”§ ë””ë²„ê¹… ë„êµ¬

### 1. API ìš”ì²­ í…ŒìŠ¤íŠ¸ ë„êµ¬

#### ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
```python
#!/usr/bin/env python3
"""
Loop AI API í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import requests
import json
import time

class APITester:
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
    
    def test_health(self):
        """ì„œë²„ ìƒíƒœ í™•ì¸"""
        try:
            response = requests.get(f"{self.base_url}/api/health", timeout=5)
            print(f"âœ… Health Check: {response.status_code}")
            print(f"Response: {response.json()}")
            return True
        except Exception as e:
            print(f"âŒ Health Check Failed: {e}")
            return False
    
    def test_name_generation(self):
        """ì´ë¦„ ìƒì„± í…ŒìŠ¤íŠ¸"""
        test_cases = [
            {"gender": "female", "style": "anime", "count": 3},
            {"gender": "male", "character_class": "ê¸°ì‚¬", "count": 2},
            {"element": "fire", "character_class": "ë§ˆë²•ì‚¬", "count": 2}
        ]
        
        for i, params in enumerate(test_cases, 1):
            print(f"\nğŸ­ Name Test {i}: {params}")
            try:
                response = requests.post(
                    f"{self.base_url}/api/names/generate",
                    json=params,
                    timeout=10
                )
                
                if response.status_code == 200:
                    data = response.json()
                    print(f"âœ… Generated {len(data['names'])} names")
                    for name in data['names']:
                        print(f"  - {name['name']} ({name.get('type', 'N/A')})")
                else:
                    print(f"âŒ Error {response.status_code}: {response.text}")
            except Exception as e:
                print(f"âŒ Test {i} Failed: {e}")
    
    def test_story_generation(self):
        """ìŠ¤í† ë¦¬ ìƒì„± í…ŒìŠ¤íŠ¸"""
        test_cases = [
            {
                "prompt": "ì§§ì€ íŒíƒ€ì§€ ì´ì•¼ê¸°",
                "genre": "fantasy",
                "max_new_tokens": 200
            },
            {
                "prompt": "ë¡œë§¨ìŠ¤ í•œ ì¥ë©´",
                "genre": "romance",
                "temperature": 0.8,
                "max_new_tokens": 150
            }
        ]
        
        for i, params in enumerate(test_cases, 1):
            print(f"\nğŸ“– Story Test {i}: {params['prompt']}")
            try:
                start_time = time.time()
                response = requests.post(
                    f"{self.base_url}/api/generate",
                    json=params,
                    timeout=30
                )
                end_time = time.time()
                
                if response.status_code == 200:
                    data = response.json()
                    print(f"âœ… Generated in {end_time - start_time:.2f}s")
                    print(f"Tokens: {data['metadata']['actual_tokens']}")
                    print(f"Story: {data['generated_text'][:100]}...")
                else:
                    print(f"âŒ Error {response.status_code}: {response.text}")
            except Exception as e:
                print(f"âŒ Test {i} Failed: {e}")
    
    def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ Starting Loop AI API Tests...")
        
        if not self.test_health():
            print("âŒ Server is not healthy. Stopping tests.")
            return
        
        self.test_name_generation()
        self.test_story_generation()
        
        print("\nâœ… All tests completed!")

if __name__ == "__main__":
    tester = APITester()
    tester.run_all_tests()
```

### 2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

#### ì„œë²„ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# monitor_api.sh

echo "ğŸ” Loop AI API ëª¨ë‹ˆí„°ë§ ì‹œì‘..."

# ì„œë²„ í”„ë¡œì„¸ìŠ¤ í™•ì¸
echo "ğŸ“Š ì„œë²„ í”„ë¡œì„¸ìŠ¤:"
ps aux | grep "python.*server.py" | grep -v grep

# í¬íŠ¸ í™•ì¸
echo -e "\nğŸ”Œ í¬íŠ¸ ìƒíƒœ:"
netstat -tlnp | grep :8000

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
echo -e "\nğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:"
free -h

# API ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸
echo -e "\nâ±ï¸ API ì‘ë‹µ ì‹œê°„:"
for i in {1..5}; do
    start_time=$(date +%s.%N)
    curl -s -o /dev/null http://localhost:8000/api/health
    end_time=$(date +%s.%N)
    response_time=$(echo "$end_time - $start_time" | bc)
    echo "Test $i: ${response_time}s"
    sleep 1
done

echo "âœ… ëª¨ë‹ˆí„°ë§ ì™„ë£Œ"
```

### 3. ë¡œê·¸ ë¶„ì„ ë„êµ¬

#### ì—ëŸ¬ íŒ¨í„´ ë¶„ì„
```python
#!/usr/bin/env python3
"""
ì„œë²„ ë¡œê·¸ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
"""

import re
from collections import Counter
from datetime import datetime

def analyze_logs(log_file="server.log"):
    """ì„œë²„ ë¡œê·¸ ë¶„ì„"""
    
    error_patterns = []
    request_counts = Counter()
    response_times = []
    
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            for line in f:
                # ì—ëŸ¬ íŒ¨í„´ ì¶”ì¶œ
                if 'ERROR' in line or 'EXCEPTION' in line:
                    error_patterns.append(line.strip())
                
                # API ìš”ì²­ ì¹´ìš´íŠ¸
                if 'POST /api/' in line or 'GET /api/' in line:
                    match = re.search(r'(GET|POST) (/api/[^\s]+)', line)
                    if match:
                        request_counts[match.group(2)] += 1
                
                # ì‘ë‹µ ì‹œê°„ (FastAPI ë¡œê·¸ì—ì„œ)
                time_match = re.search(r'(\d+\.\d+)ms', line)
                if time_match:
                    response_times.append(float(time_match.group(1)))
    
    except FileNotFoundError:
        print(f"âŒ ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {log_file}")
        return
    
    # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ“Š ë¡œê·¸ ë¶„ì„ ê²°ê³¼ ({log_file})")
    print("=" * 50)
    
    if error_patterns:
        print(f"\nâŒ ì—ëŸ¬ íŒ¨í„´ ({len(error_patterns)}ê°œ):")
        for error in error_patterns[-5:]:  # ìµœê·¼ 5ê°œë§Œ
            print(f"  {error}")
    
    if request_counts:
        print(f"\nğŸ“ˆ API ìš”ì²­ í†µê³„:")
        for endpoint, count in request_counts.most_common(5):
            print(f"  {endpoint}: {count}íšŒ")
    
    if response_times:
        avg_time = sum(response_times) / len(response_times)
        max_time = max(response_times)
        print(f"\nâ±ï¸ ì‘ë‹µ ì‹œê°„:")
        print(f"  í‰ê· : {avg_time:.2f}ms")
        print(f"  ìµœëŒ€: {max_time:.2f}ms")
        print(f"  ìƒ˜í”Œ ìˆ˜: {len(response_times)}")

if __name__ == "__main__":
    analyze_logs()
```

## ğŸ†˜ ê¸´ê¸‰ ë³µêµ¬ ê°€ì´ë“œ

### ì„œë²„ ì™„ì „ ë‹¤ìš´ ì‹œ

1. **ê¸´ê¸‰ ì¬ì‹œì‘**
   ```bash
   #!/bin/bash
   # emergency_restart.sh
   
   echo "ğŸš¨ ê¸´ê¸‰ ì„œë²„ ì¬ì‹œì‘..."
   
   # ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
   pkill -f "python.*server.py"
   sleep 2
   
   # í¬íŠ¸ ì •ë¦¬
   fuser -k 8000/tcp 2>/dev/null
   
   # ê°€ìƒí™˜ê²½ í™œì„±í™” ë° ì„œë²„ ì‹œì‘
   cd /Users/user/loop/loop_ai
   source venv/bin/activate
   nohup python src/inference/server.py > server.log 2>&1 &
   
   # í—¬ìŠ¤ì²´í¬
   sleep 5
   if curl -s http://localhost:8000/api/health > /dev/null; then
       echo "âœ… ì„œë²„ ë³µêµ¬ ì„±ê³µ"
   else
       echo "âŒ ì„œë²„ ë³µêµ¬ ì‹¤íŒ¨"
   fi
   ```

2. **ì„¤ì • ì´ˆê¸°í™”**
   ```bash
   # ìºì‹œ ì •ë¦¬
   rm -rf __pycache__/ src/**/__pycache__/
   
   # ì˜ì¡´ì„± ì¬ì„¤ì¹˜
   pip install -r requirements.txt
   
   # ëª¨ë¸ ì¬ë‹¤ìš´ë¡œë“œ (í•„ìš”ì‹œ)
   python scripts/download_qwen_models.py
   ```

---

**ê´€ë ¨ ë¬¸ì„œ:**
- [ë©”ì¸ API ë¬¸ì„œ](./README.md)
- [Fantasy Name Generator API](./fantasy-names.md)
- [Story Generator API](./story-generator.md)
- [ì‚¬ìš© ì˜ˆì œ](./examples.md)

**ì¶”ê°€ ì§€ì›:**
- ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§: `tail -f server.log`
- ì¸í„°ë™í‹°ë¸Œ API ë¬¸ì„œ: http://localhost:8000/api/docs
- ê±´ê°• ìƒíƒœ í™•ì¸: http://localhost:8000/api/health 